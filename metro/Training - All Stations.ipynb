{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOURS_PER_DAY = 20\n",
    "DAYS_PER_WEEK = 7\n",
    "DAYS_PER_YEAR = 365\n",
    "\n",
    "def create_dataset_years(signal_data, hours=1, days=1, weeks=1, years=1):\n",
    "    num_data = len(signal_data) - HOURS_PER_DAY * DAYS_PER_YEAR * years\n",
    "    x_arr, y_arr = np.zeros((num_data, 4, max(hours, days, weeks, years))), np.zeros((num_data,))\n",
    "    \n",
    "    for i in range(num_data):\n",
    "        index = i\n",
    "        \n",
    "        for j in range(years):\n",
    "            x_arr[i, 3, j] = signal_data[index]\n",
    "            index += HOURS_PER_DAY * DAYS_PER_YEAR\n",
    "            \n",
    "        index -= HOURS_PER_DAY * DAYS_PER_WEEK * weeks\n",
    "        \n",
    "        for j in range(weeks):\n",
    "            x_arr[i, 2, j] = signal_data[index]\n",
    "            index += HOURS_PER_DAY * DAYS_PER_WEEK\n",
    "            \n",
    "        index -= HOURS_PER_DAY * days\n",
    "        \n",
    "        for j in range(days):\n",
    "            x_arr[i, 1, j] = signal_data[index]\n",
    "            index += HOURS_PER_DAY\n",
    "        \n",
    "        x_arr[i, 0, 0:hours] = signal_data[(index-hours):index]\n",
    "        y_arr[i] = signal_data[index]\n",
    "\n",
    "    return x_arr, y_arr\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()  \n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.2)) \n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def run_model(data):\n",
    "    hours = 3\n",
    "    days = 4\n",
    "    weeks = 5\n",
    "    years = 5\n",
    "    batch_size = 256\n",
    "    \n",
    "    # create model\n",
    "    model = create_model()\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "    \n",
    "    # prepare data\n",
    "    x_data, y_data = create_dataset_years(data, hours, days, weeks, years)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, shuffle=False)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # run model\n",
    "    history = model.fit(x_train, y_train, epochs=200, batch_size=batch_size, validation_data=(x_val, y_val))\n",
    "    score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    # predict future values\n",
    "    predictions = np.concatenate(model.predict(x_test, batch_size))\n",
    "    #plt.plot(predictions, (predictions - y_test), 'rx')\n",
    "    \n",
    "    # evaluate model\n",
    "    SMAPE = np.mean(abs(predictions - y_test) / (abs(predictions) + abs(y_test)))\n",
    "    RMSE = np.sqrt(np.mean((predictions - y_test)**2))\n",
    "    \n",
    "    return SMAPE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing station number 150\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 11s 490us/step - loss: 0.0096 - val_loss: 0.0023\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 4s 189us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0017 - val_loss: 9.9622e-04\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0016 - val_loss: 9.8598e-04\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0017 - val_loss: 9.6208e-04\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0016 - val_loss: 9.0284e-04\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0016 - val_loss: 9.8022e-04\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0015 - val_loss: 8.7194e-04\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0016 - val_loss: 8.3441e-04\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 0.0015 - val_loss: 8.5182e-04\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0015 - val_loss: 8.5995e-04\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 0.0015 - val_loss: 8.9445e-04\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 0.0015 - val_loss: 8.3983e-04\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0015 - val_loss: 8.6283e-04\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 0.0015 - val_loss: 8.4522e-04\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0015 - val_loss: 9.5561e-04\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0015 - val_loss: 9.8325e-04\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0015 - val_loss: 8.5423e-04\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0015 - val_loss: 8.9163e-04\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0015 - val_loss: 9.4754e-04\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0015 - val_loss: 9.5084e-04\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 0.0015 - val_loss: 8.1884e-04\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0014 - val_loss: 8.6981e-04\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0014 - val_loss: 8.2304e-04\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0014 - val_loss: 8.2612e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0014 - val_loss: 8.4484e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0014 - val_loss: 8.1193e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 5s 214us/step - loss: 0.0014 - val_loss: 8.6076e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 5s 206us/step - loss: 0.0014 - val_loss: 8.6548e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 5s 204us/step - loss: 0.0014 - val_loss: 8.7606e-04\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 5s 204us/step - loss: 0.0014 - val_loss: 9.2093e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 0.0013 - val_loss: 8.3326e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0014 - val_loss: 8.0944e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 0.0013 - val_loss: 7.8103e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0013 - val_loss: 8.0972e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0013 - val_loss: 8.3185e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 0.0013 - val_loss: 7.7075e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0013 - val_loss: 8.5973e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0013 - val_loss: 7.7741e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 0.0013 - val_loss: 9.4719e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0013 - val_loss: 8.0471e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 6s 272us/step - loss: 0.0013 - val_loss: 9.5220e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 5s 233us/step - loss: 0.0013 - val_loss: 8.0112e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 0.0013 - val_loss: 7.7904e-04\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 0.0013 - val_loss: 7.4069e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 0.0013 - val_loss: 7.5549e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 0.0013 - val_loss: 8.0686e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 5s 220us/step - loss: 0.0013 - val_loss: 7.7878e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 0.0013 - val_loss: 7.4786e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 0.0012 - val_loss: 7.5871e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 0.0012 - val_loss: 7.0437e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0012 - val_loss: 6.9424e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0012 - val_loss: 7.0990e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0012 - val_loss: 6.9471e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0012 - val_loss: 7.3056e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 0.0012 - val_loss: 7.0232e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0012 - val_loss: 6.5091e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 4s 197us/step - loss: 0.0012 - val_loss: 7.0881e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0012 - val_loss: 6.6811e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 4s 191us/step - loss: 0.0012 - val_loss: 7.5511e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 0.0011 - val_loss: 6.3201e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 5s 206us/step - loss: 0.0011 - val_loss: 6.4409e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 0.0011 - val_loss: 6.8441e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 0.0011 - val_loss: 6.4987e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 0.0011 - val_loss: 6.1711e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 0.0011 - val_loss: 6.0370e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 0.0011 - val_loss: 6.2065e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 0.0011 - val_loss: 6.0804e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 0.0011 - val_loss: 6.7726e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 0.0011 - val_loss: 5.7999e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0011 - val_loss: 5.8885e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0011 - val_loss: 5.8150e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 0.0010 - val_loss: 6.6328e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 0.0010 - val_loss: 5.6101e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0010 - val_loss: 5.5793e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0011 - val_loss: 5.7911e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 4s 194us/step - loss: 0.0011 - val_loss: 6.0617e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 0.0010 - val_loss: 5.5026e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 0.0010 - val_loss: 5.4330e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 0.0010 - val_loss: 5.3057e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 9.7982e-04 - val_loss: 5.2000e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 9.8128e-04 - val_loss: 5.6667e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0010 - val_loss: 5.1237e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 5s 204us/step - loss: 9.7194e-04 - val_loss: 5.1324e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 5s 214us/step - loss: 9.4848e-04 - val_loss: 5.1216e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 5s 229us/step - loss: 9.3569e-04 - val_loss: 5.2075e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 9.5741e-04 - val_loss: 5.3480e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 9.3897e-04 - val_loss: 5.5201e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 9.2967e-04 - val_loss: 5.5875e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 9.6462e-04 - val_loss: 5.5682e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 9.1639e-04 - val_loss: 5.3484e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 5s 216us/step - loss: 9.2634e-04 - val_loss: 5.4422e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 7s 294us/step - loss: 9.3858e-04 - val_loss: 5.0099e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 7s 306us/step - loss: 9.3316e-04 - val_loss: 4.9842e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 5s 215us/step - loss: 9.1910e-04 - val_loss: 4.9078e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 5s 220us/step - loss: 9.2416e-04 - val_loss: 4.9976e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 5s 219us/step - loss: 8.8504e-04 - val_loss: 4.9042e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 8.8050e-04 - val_loss: 4.9182e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 8.8249e-04 - val_loss: 5.0095e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 8.7065e-04 - val_loss: 4.9744e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 8.6466e-04 - val_loss: 5.2223e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 8.9042e-04 - val_loss: 5.4794e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 8.8607e-04 - val_loss: 5.2287e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 4s 196us/step - loss: 8.4851e-04 - val_loss: 4.8488e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 8.4842e-04 - val_loss: 5.9814e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 8.7569e-04 - val_loss: 5.2179e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 8.2240e-04 - val_loss: 4.8906e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 8.0719e-04 - val_loss: 4.9068e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 8.3778e-04 - val_loss: 5.2799e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 8.3662e-04 - val_loss: 5.2172e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 8.0282e-04 - val_loss: 5.0642e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 8.3996e-04 - val_loss: 4.6712e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 7.9272e-04 - val_loss: 5.0323e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 8.0216e-04 - val_loss: 4.9385e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 7.8950e-04 - val_loss: 4.7940e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 8.1761e-04 - val_loss: 4.7125e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 8.1633e-04 - val_loss: 4.9400e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.8888e-04 - val_loss: 4.8378e-04\n",
      "Epoch 145/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 3s 145us/step - loss: 8.4110e-04 - val_loss: 4.6425e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 8.1201e-04 - val_loss: 4.9182e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.9204e-04 - val_loss: 4.9826e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.6197e-04 - val_loss: 4.8002e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.7507e-04 - val_loss: 4.6703e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.6604e-04 - val_loss: 4.7644e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 8.5474e-04 - val_loss: 4.9523e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.7367e-04 - val_loss: 5.1338e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.5682e-04 - val_loss: 4.5050e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.4226e-04 - val_loss: 4.8302e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 7.5614e-04 - val_loss: 5.0072e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.5210e-04 - val_loss: 4.9421e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.4022e-04 - val_loss: 4.7158e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.5046e-04 - val_loss: 4.6414e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.6728e-04 - val_loss: 4.9407e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.8386e-04 - val_loss: 4.9631e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.9124e-04 - val_loss: 5.1561e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 7.5978e-04 - val_loss: 4.5893e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.5459e-04 - val_loss: 5.1651e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.4361e-04 - val_loss: 4.5815e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 7.3442e-04 - val_loss: 4.5611e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 7.4390e-04 - val_loss: 4.6858e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.2864e-04 - val_loss: 4.8079e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.4621e-04 - val_loss: 4.4607e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.2772e-04 - val_loss: 4.7757e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.1650e-04 - val_loss: 4.4914e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.5305e-04 - val_loss: 4.6547e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.6420e-04 - val_loss: 4.4625e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.2971e-04 - val_loss: 4.6221e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.4030e-04 - val_loss: 5.3101e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.3637e-04 - val_loss: 4.4045e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.2411e-04 - val_loss: 4.6683e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 5s 214us/step - loss: 7.2853e-04 - val_loss: 5.1701e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 4s 197us/step - loss: 7.5374e-04 - val_loss: 4.5250e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 5s 209us/step - loss: 7.1116e-04 - val_loss: 4.5372e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 7.0877e-04 - val_loss: 4.8856e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 7.0126e-04 - val_loss: 4.4524e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 7.0489e-04 - val_loss: 4.4487e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 6.9310e-04 - val_loss: 5.0321e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 6.9967e-04 - val_loss: 4.6021e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 7.0125e-04 - val_loss: 4.6798e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 6.9913e-04 - val_loss: 4.7567e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 7.2314e-04 - val_loss: 4.5424e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 7.0121e-04 - val_loss: 4.7078e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 6.9983e-04 - val_loss: 4.4696e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 6.8533e-04 - val_loss: 4.5415e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 7.1391e-04 - val_loss: 4.6112e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.8547e-04 - val_loss: 4.4187e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.7930e-04 - val_loss: 4.3915e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.8158e-04 - val_loss: 4.7151e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 7.1988e-04 - val_loss: 4.7762e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 7.0008e-04 - val_loss: 4.6642e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 6.9849e-04 - val_loss: 4.5156e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 6.7629e-04 - val_loss: 4.9261e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 7.2871e-04 - val_loss: 4.9825e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.8063e-04 - val_loss: 4.4384e-04\n",
      "6944/6944 [==============================] - 0s 37us/step\n",
      "Now processing station number 151\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 10s 472us/step - loss: 0.0023 - val_loss: 8.9185e-04\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 8.2882e-04 - val_loss: 7.9769e-04\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.9769e-04 - val_loss: 7.2027e-04\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.6344e-04 - val_loss: 6.8355e-04\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.4599e-04 - val_loss: 7.5729e-04\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.3276e-04 - val_loss: 6.4102e-04\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.1364e-04 - val_loss: 6.3270e-04\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.2916e-04 - val_loss: 7.3595e-04\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 7.0677e-04 - val_loss: 6.3366e-04\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.0109e-04 - val_loss: 6.5536e-04\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.9877e-04 - val_loss: 6.2333e-04\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.8907e-04 - val_loss: 6.1836e-04\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.9460e-04 - val_loss: 6.0554e-04\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.8944e-04 - val_loss: 7.2666e-04\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 7.0334e-04 - val_loss: 5.9599e-04\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.5787e-04 - val_loss: 6.2456e-04\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.5610e-04 - val_loss: 5.7361e-04\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.6621e-04 - val_loss: 6.4595e-04\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.7670e-04 - val_loss: 5.8561e-04\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.6996e-04 - val_loss: 5.5695e-04\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.4796e-04 - val_loss: 7.2518e-04\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.4530e-04 - val_loss: 5.3856e-04\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.5869e-04 - val_loss: 5.3839e-04\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.6823e-04 - val_loss: 5.3075e-04\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.2383e-04 - val_loss: 5.2268e-04\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.0877e-04 - val_loss: 4.9105e-04\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 5.9902e-04 - val_loss: 4.7438e-04\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 6.2707e-04 - val_loss: 4.5939e-04\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 6.0920e-04 - val_loss: 4.5154e-04\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 5.8742e-04 - val_loss: 4.8184e-04\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.9988e-04 - val_loss: 4.2454e-04\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.8590e-04 - val_loss: 4.0737e-04\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.8736e-04 - val_loss: 4.5014e-04\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.5358e-04 - val_loss: 4.1203e-04\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.5199e-04 - val_loss: 4.2267e-04\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.6866e-04 - val_loss: 4.6518e-04\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.4371e-04 - val_loss: 3.9481e-04\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.2683e-04 - val_loss: 3.7622e-04\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.4394e-04 - val_loss: 3.8392e-04\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1316e-04 - val_loss: 3.6351e-04\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.0766e-04 - val_loss: 3.5474e-04\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.2250e-04 - val_loss: 5.1130e-04\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.0210e-04 - val_loss: 3.4368e-04\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 5.0094e-04 - val_loss: 3.6127e-04\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.9379e-04 - val_loss: 3.6249e-04\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.0464e-04 - val_loss: 3.4830e-04\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.8785e-04 - val_loss: 3.6656e-04\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.8218e-04 - val_loss: 3.3209e-04\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 4.7425e-04 - val_loss: 3.4898e-04\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.7174e-04 - val_loss: 3.5441e-04\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.7170e-04 - val_loss: 3.2639e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.7042e-04 - val_loss: 4.2237e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.5506e-04 - val_loss: 3.0428e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 4.5332e-04 - val_loss: 3.2011e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.3419e-04 - val_loss: 2.9453e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.3109e-04 - val_loss: 3.3859e-04\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.1461e-04 - val_loss: 3.1304e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.2146e-04 - val_loss: 3.0607e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.1254e-04 - val_loss: 2.9303e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 4.0264e-04 - val_loss: 2.9612e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 3.8788e-04 - val_loss: 3.1083e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.9004e-04 - val_loss: 2.5053e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 3.8640e-04 - val_loss: 2.6999e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.7269e-04 - val_loss: 2.7894e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.6572e-04 - val_loss: 2.4125e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.6659e-04 - val_loss: 2.6466e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.5634e-04 - val_loss: 2.2036e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 3.5650e-04 - val_loss: 2.3327e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.4451e-04 - val_loss: 2.1261e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 3.5812e-04 - val_loss: 2.4552e-04\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 3.4058e-04 - val_loss: 2.4205e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.3955e-04 - val_loss: 2.1456e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 3.3833e-04 - val_loss: 2.2602e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 3.2307e-04 - val_loss: 2.0487e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 4s 191us/step - loss: 3.2837e-04 - val_loss: 2.2704e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 5s 243us/step - loss: 3.1945e-04 - val_loss: 2.1404e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 4s 197us/step - loss: 3.1195e-04 - val_loss: 2.5912e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 5s 244us/step - loss: 3.2603e-04 - val_loss: 2.1415e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 3.2288e-04 - val_loss: 2.1461e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 3.0541e-04 - val_loss: 1.8562e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 5s 204us/step - loss: 3.1189e-04 - val_loss: 1.6405e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 5s 226us/step - loss: 2.9969e-04 - val_loss: 1.8295e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 3.2175e-04 - val_loss: 2.0501e-04\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 4s 177us/step - loss: 2.8932e-04 - val_loss: 1.6789e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 2.9416e-04 - val_loss: 1.6674e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 2.7536e-04 - val_loss: 1.6825e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 2.8913e-04 - val_loss: 2.2881e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 2.8316e-04 - val_loss: 1.8791e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 2.8197e-04 - val_loss: 2.0627e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 2.7480e-04 - val_loss: 1.9009e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 2.7499e-04 - val_loss: 1.9186e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 2.7141e-04 - val_loss: 1.9887e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 2.8444e-04 - val_loss: 2.0016e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 2.6829e-04 - val_loss: 1.6505e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 2.5818e-04 - val_loss: 1.6882e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 2.5928e-04 - val_loss: 2.0447e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 2.6820e-04 - val_loss: 1.7140e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 2.7207e-04 - val_loss: 1.8813e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 4s 191us/step - loss: 2.6905e-04 - val_loss: 1.8572e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 4s 189us/step - loss: 2.5851e-04 - val_loss: 1.6514e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 2.5434e-04 - val_loss: 1.7200e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 2.6216e-04 - val_loss: 1.9127e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 2.5286e-04 - val_loss: 2.1120e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 2.5162e-04 - val_loss: 1.8191e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 2.4492e-04 - val_loss: 1.7900e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 2.5399e-04 - val_loss: 1.7404e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 2.4708e-04 - val_loss: 1.8185e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 2.4667e-04 - val_loss: 1.5831e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 2.7281e-04 - val_loss: 2.0238e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 2.5979e-04 - val_loss: 1.8940e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 2.4403e-04 - val_loss: 1.5571e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 2.4093e-04 - val_loss: 1.5117e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 2.5529e-04 - val_loss: 1.4469e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 2.4416e-04 - val_loss: 1.5876e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 5s 223us/step - loss: 2.3948e-04 - val_loss: 1.5253e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 5s 206us/step - loss: 2.4995e-04 - val_loss: 1.9035e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 5s 215us/step - loss: 2.4336e-04 - val_loss: 1.5313e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 6s 251us/step - loss: 2.4030e-04 - val_loss: 1.4789e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 5s 234us/step - loss: 2.3773e-04 - val_loss: 1.3702e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 2.3247e-04 - val_loss: 1.5232e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 5s 203us/step - loss: 2.4000e-04 - val_loss: 2.4753e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 6s 259us/step - loss: 2.4232e-04 - val_loss: 1.7434e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 5s 218us/step - loss: 2.2965e-04 - val_loss: 1.5326e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 5s 213us/step - loss: 2.4603e-04 - val_loss: 1.8267e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 5s 210us/step - loss: 2.3021e-04 - val_loss: 1.4264e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 5s 218us/step - loss: 2.2493e-04 - val_loss: 1.7288e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 2.2599e-04 - val_loss: 1.5367e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 2.2938e-04 - val_loss: 1.9493e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 2.3036e-04 - val_loss: 1.4063e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 2.1739e-04 - val_loss: 1.7488e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 2.3107e-04 - val_loss: 1.5523e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 2.3444e-04 - val_loss: 1.4609e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 2.2804e-04 - val_loss: 1.4517e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 5s 227us/step - loss: 2.3862e-04 - val_loss: 1.4632e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 4s 197us/step - loss: 2.2331e-04 - val_loss: 1.4594e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 2.3069e-04 - val_loss: 1.5950e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 4s 194us/step - loss: 2.1636e-04 - val_loss: 1.6617e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 2.2305e-04 - val_loss: 1.4361e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 2.2948e-04 - val_loss: 1.4595e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 2.1254e-04 - val_loss: 1.4078e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 2.1843e-04 - val_loss: 1.7970e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 4s 194us/step - loss: 2.1972e-04 - val_loss: 1.4498e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 2.1787e-04 - val_loss: 1.6549e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 2.1960e-04 - val_loss: 1.4014e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 2.2184e-04 - val_loss: 1.5169e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 2.3603e-04 - val_loss: 1.5108e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 2.1755e-04 - val_loss: 1.5627e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 2.3109e-04 - val_loss: 1.9564e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 2.2666e-04 - val_loss: 1.7575e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 2.3091e-04 - val_loss: 1.8325e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 2.2399e-04 - val_loss: 1.3374e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 2.0465e-04 - val_loss: 1.5860e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 2.2274e-04 - val_loss: 1.7472e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 2.1083e-04 - val_loss: 1.4334e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 2.1855e-04 - val_loss: 1.4498e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 2.1245e-04 - val_loss: 1.5003e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 2.0745e-04 - val_loss: 1.4361e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 2.0870e-04 - val_loss: 1.8061e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 2.2353e-04 - val_loss: 1.4146e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 2.1330e-04 - val_loss: 1.3176e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 5s 209us/step - loss: 2.0099e-04 - val_loss: 1.3720e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 2.1529e-04 - val_loss: 1.4324e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 2.1321e-04 - val_loss: 1.2415e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 2.0704e-04 - val_loss: 1.4130e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 2.0737e-04 - val_loss: 1.5360e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 2.0519e-04 - val_loss: 1.5339e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 2.0622e-04 - val_loss: 1.6244e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 1.9749e-04 - val_loss: 1.5540e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 2.1237e-04 - val_loss: 1.4561e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 2.0684e-04 - val_loss: 1.4845e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 2.1165e-04 - val_loss: 1.3299e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 2.0975e-04 - val_loss: 1.5193e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 2.0786e-04 - val_loss: 1.2678e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 1.9663e-04 - val_loss: 1.3575e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 2.0244e-04 - val_loss: 1.3114e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 2.0030e-04 - val_loss: 1.6855e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 1.9954e-04 - val_loss: 1.7276e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 1.9316e-04 - val_loss: 1.4097e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 2.1245e-04 - val_loss: 1.4675e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 2.1730e-04 - val_loss: 1.3283e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 1.9868e-04 - val_loss: 1.5413e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 2.0414e-04 - val_loss: 1.3906e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 1.8788e-04 - val_loss: 1.4390e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 2.0446e-04 - val_loss: 1.6592e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 1.8825e-04 - val_loss: 1.7179e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 2.0945e-04 - val_loss: 1.4194e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 2.0262e-04 - val_loss: 1.4570e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 1.9434e-04 - val_loss: 1.3384e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 1.9556e-04 - val_loss: 1.5011e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 3s 143us/step - loss: 1.8854e-04 - val_loss: 1.4796e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 1.9662e-04 - val_loss: 1.7400e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 2.0596e-04 - val_loss: 1.5241e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 1.9206e-04 - val_loss: 1.3927e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 1.9937e-04 - val_loss: 1.3220e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 1.9046e-04 - val_loss: 1.3663e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 1.8594e-04 - val_loss: 1.5548e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 2.0110e-04 - val_loss: 1.8404e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 1.9950e-04 - val_loss: 1.6420e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 1.9950e-04 - val_loss: 1.4775e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 1.8983e-04 - val_loss: 1.3035e-04\n",
      "6944/6944 [==============================] - 0s 36us/step\n",
      "Now processing station number 152\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 11s 494us/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 3s 144us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 6s 257us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 5s 218us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 6s 256us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 5s 233us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 4s 189us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 5s 217us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0013 - val_loss: 9.4413e-04\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 0.0013 - val_loss: 8.9691e-04\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 0.0012 - val_loss: 9.0672e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 0.0012 - val_loss: 8.4367e-04\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 0.0012 - val_loss: 7.9673e-04\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 0.0012 - val_loss: 8.6386e-04\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0012 - val_loss: 7.9266e-04\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0012 - val_loss: 7.9939e-04\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0012 - val_loss: 8.3948e-04\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0012 - val_loss: 8.3425e-04\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0011 - val_loss: 7.5126e-04\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0011 - val_loss: 7.8090e-04\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0011 - val_loss: 7.1635e-04\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 5s 224us/step - loss: 0.0011 - val_loss: 7.4372e-04\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 5s 220us/step - loss: 0.0011 - val_loss: 7.2030e-04\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 6s 267us/step - loss: 0.0011 - val_loss: 7.4660e-04\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 5s 222us/step - loss: 0.0011 - val_loss: 7.3500e-04\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 5s 205us/step - loss: 0.0011 - val_loss: 7.1668e-04\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0011 - val_loss: 7.2521e-04\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 0.0011 - val_loss: 6.7805e-04\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 0.0011 - val_loss: 7.7156e-04\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0010 - val_loss: 6.9884e-04\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 0.0010 - val_loss: 6.7164e-04\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 0.0010 - val_loss: 6.8121e-04\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 9.9193e-04 - val_loss: 6.6350e-04\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 9.9236e-04 - val_loss: 6.8741e-04\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 5s 244us/step - loss: 9.7668e-04 - val_loss: 6.5483e-04\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 6s 249us/step - loss: 9.7948e-04 - val_loss: 6.3610e-04\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 6s 255us/step - loss: 9.5800e-04 - val_loss: 6.3255e-04\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 9.2126e-04 - val_loss: 6.1321e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 9.1794e-04 - val_loss: 8.0098e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 9.0441e-04 - val_loss: 6.6158e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 9.0747e-04 - val_loss: 5.8357e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 8.8872e-04 - val_loss: 5.3394e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 8.6054e-04 - val_loss: 5.1007e-04\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 8.3424e-04 - val_loss: 4.9059e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 8.3636e-04 - val_loss: 4.7413e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 8.0948e-04 - val_loss: 4.6352e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 7.9964e-04 - val_loss: 4.6573e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 8.0117e-04 - val_loss: 4.5379e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.9231e-04 - val_loss: 3.9822e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.5977e-04 - val_loss: 4.4114e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 7.7324e-04 - val_loss: 4.8066e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.5078e-04 - val_loss: 4.0014e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.4366e-04 - val_loss: 4.0777e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 7.5880e-04 - val_loss: 4.4881e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 7.6539e-04 - val_loss: 3.7525e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 7.1763e-04 - val_loss: 3.6759e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.0760e-04 - val_loss: 3.9219e-04\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 7.1096e-04 - val_loss: 3.9365e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 7.1946e-04 - val_loss: 4.2512e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 6.9361e-04 - val_loss: 3.9208e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.9974e-04 - val_loss: 3.9642e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.9080e-04 - val_loss: 3.2730e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 7.0258e-04 - val_loss: 4.2112e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.0154e-04 - val_loss: 4.4453e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.0633e-04 - val_loss: 3.3454e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.6258e-04 - val_loss: 4.1848e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.7692e-04 - val_loss: 3.3071e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 6.7365e-04 - val_loss: 3.8650e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 6.9077e-04 - val_loss: 3.9399e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.6978e-04 - val_loss: 3.8470e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.9148e-04 - val_loss: 5.8792e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.8167e-04 - val_loss: 3.9936e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.6319e-04 - val_loss: 3.7231e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 6.9805e-04 - val_loss: 3.7940e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 6.6401e-04 - val_loss: 3.9478e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.4899e-04 - val_loss: 3.9528e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.6142e-04 - val_loss: 3.2896e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.6303e-04 - val_loss: 3.3015e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.3344e-04 - val_loss: 3.5251e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.4235e-04 - val_loss: 3.9415e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 6.5465e-04 - val_loss: 3.4341e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 6.3178e-04 - val_loss: 3.2570e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 6.2784e-04 - val_loss: 3.7960e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.1534e-04 - val_loss: 4.0250e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.4563e-04 - val_loss: 3.4477e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.3973e-04 - val_loss: 3.4651e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 6.1742e-04 - val_loss: 3.2237e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 5.9941e-04 - val_loss: 3.1597e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 6.0486e-04 - val_loss: 3.1374e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.5904e-04 - val_loss: 3.7245e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 6.1706e-04 - val_loss: 3.0887e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.0894e-04 - val_loss: 3.7313e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 5.9718e-04 - val_loss: 3.4272e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 6.2386e-04 - val_loss: 2.9995e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.0624e-04 - val_loss: 3.0245e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 6.0507e-04 - val_loss: 3.4466e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.0326e-04 - val_loss: 3.1315e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.2199e-04 - val_loss: 3.1834e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.9397e-04 - val_loss: 3.3940e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.8769e-04 - val_loss: 3.5389e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.8259e-04 - val_loss: 3.4463e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 5.9050e-04 - val_loss: 3.2373e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.0704e-04 - val_loss: 4.1181e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.6651e-04 - val_loss: 3.0852e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.8435e-04 - val_loss: 3.2268e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.8144e-04 - val_loss: 3.1812e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.9925e-04 - val_loss: 3.7817e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 5.9537e-04 - val_loss: 2.8232e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 5.8950e-04 - val_loss: 4.4296e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 5.9717e-04 - val_loss: 3.9000e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 5.7048e-04 - val_loss: 2.7803e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 5.5432e-04 - val_loss: 3.1864e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 5.9386e-04 - val_loss: 3.0019e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.6445e-04 - val_loss: 2.9721e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.6544e-04 - val_loss: 3.1021e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 5.7864e-04 - val_loss: 2.8164e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.7307e-04 - val_loss: 3.0817e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 5.7158e-04 - val_loss: 2.8347e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 5.6784e-04 - val_loss: 2.6021e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.5392e-04 - val_loss: 2.8797e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.6472e-04 - val_loss: 3.5018e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.7013e-04 - val_loss: 3.1413e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 5.4779e-04 - val_loss: 2.5515e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.7722e-04 - val_loss: 3.0933e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.7451e-04 - val_loss: 2.8917e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.2623e-04 - val_loss: 2.8916e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.4176e-04 - val_loss: 2.6977e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.9139e-04 - val_loss: 3.8142e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1404e-04 - val_loss: 2.6882e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.1836e-04 - val_loss: 3.3894e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.4540e-04 - val_loss: 2.8904e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.1655e-04 - val_loss: 2.8771e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.4578e-04 - val_loss: 3.3587e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.4653e-04 - val_loss: 3.2860e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.5669e-04 - val_loss: 2.8999e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 5.1096e-04 - val_loss: 2.7922e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 5.3636e-04 - val_loss: 3.0061e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 5.3804e-04 - val_loss: 2.9580e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 5.2209e-04 - val_loss: 3.0485e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.3511e-04 - val_loss: 2.8331e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1700e-04 - val_loss: 3.0185e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.0733e-04 - val_loss: 2.5574e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.1371e-04 - val_loss: 3.3471e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 5.2121e-04 - val_loss: 2.8474e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.1889e-04 - val_loss: 2.4891e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.9448e-04 - val_loss: 2.5267e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 5.2152e-04 - val_loss: 3.4074e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.8667e-04 - val_loss: 2.7329e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.2740e-04 - val_loss: 2.4154e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1122e-04 - val_loss: 2.5604e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.9850e-04 - val_loss: 2.7373e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.1508e-04 - val_loss: 3.1548e-04\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.1968e-04 - val_loss: 2.7758e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.9298e-04 - val_loss: 2.8177e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.8303e-04 - val_loss: 2.8023e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8593e-04 - val_loss: 2.9467e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.9652e-04 - val_loss: 2.7131e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.9047e-04 - val_loss: 2.8178e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.8239e-04 - val_loss: 2.8755e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.7449e-04 - val_loss: 2.4234e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.7527e-04 - val_loss: 2.8080e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.0570e-04 - val_loss: 2.7820e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.0653e-04 - val_loss: 2.8804e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 4.6513e-04 - val_loss: 2.7253e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 6s 257us/step - loss: 5.0028e-04 - val_loss: 2.9184e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 7s 332us/step - loss: 4.8191e-04 - val_loss: 2.6668e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 5s 212us/step - loss: 4.9033e-04 - val_loss: 2.8443e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.7127e-04 - val_loss: 2.8351e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.8795e-04 - val_loss: 3.5991e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 4.5671e-04 - val_loss: 2.4333e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 4.6961e-04 - val_loss: 2.6153e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.6517e-04 - val_loss: 2.6035e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 4.6249e-04 - val_loss: 2.3863e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 4.6277e-04 - val_loss: 2.5423e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 4.7014e-04 - val_loss: 2.5039e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.4642e-04 - val_loss: 2.8062e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.5573e-04 - val_loss: 2.5121e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 4.6539e-04 - val_loss: 3.3019e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.6957e-04 - val_loss: 2.8688e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.4501e-04 - val_loss: 2.5213e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.3676e-04 - val_loss: 2.5062e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 4.6752e-04 - val_loss: 2.2617e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.4238e-04 - val_loss: 2.3359e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.3119e-04 - val_loss: 2.4388e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.2372e-04 - val_loss: 2.5440e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.5874e-04 - val_loss: 2.6232e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.3830e-04 - val_loss: 2.3921e-04\n",
      "6944/6944 [==============================] - 0s 38us/step\n",
      "Now processing station number 153\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 12s 547us/step - loss: 0.0062 - val_loss: 0.0012\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 6s 252us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 0.0013 - val_loss: 9.3670e-04\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0013 - val_loss: 9.0811e-04\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 0.0013 - val_loss: 8.9169e-04\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0012 - val_loss: 9.4321e-04\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0012 - val_loss: 8.8638e-04\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0012 - val_loss: 8.6123e-04\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0012 - val_loss: 8.7971e-04\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0012 - val_loss: 8.3397e-04\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0012 - val_loss: 8.5525e-04\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0011 - val_loss: 8.1568e-04\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0012 - val_loss: 8.0673e-04\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0011 - val_loss: 7.9148e-04\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 0.0011 - val_loss: 8.0558e-04\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 0.0011 - val_loss: 8.0235e-04\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0011 - val_loss: 7.4784e-04\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0011 - val_loss: 7.4072e-04\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 0.0011 - val_loss: 7.4586e-04\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0010 - val_loss: 7.2445e-04\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0010 - val_loss: 7.3110e-04\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.9931e-04 - val_loss: 6.6505e-04\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 9.7161e-04 - val_loss: 6.8436e-04\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 9.6722e-04 - val_loss: 6.7288e-04\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 9.3700e-04 - val_loss: 6.1860e-04\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 9.4649e-04 - val_loss: 7.2948e-04\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 9.1792e-04 - val_loss: 7.3621e-04\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 9.1762e-04 - val_loss: 6.7680e-04\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.0233e-04 - val_loss: 5.9614e-04\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1390e-04 - val_loss: 6.5563e-04\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 8.5049e-04 - val_loss: 5.5726e-04\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 8.7547e-04 - val_loss: 6.1623e-04\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 8.5995e-04 - val_loss: 5.4366e-04\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 8.3596e-04 - val_loss: 5.3803e-04\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 8.4463e-04 - val_loss: 5.6466e-04\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.2040e-04 - val_loss: 5.3673e-04\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.9834e-04 - val_loss: 6.0371e-04\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 8.0161e-04 - val_loss: 5.0422e-04\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 8.0320e-04 - val_loss: 5.4178e-04\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.9573e-04 - val_loss: 5.7588e-04\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 7.8503e-04 - val_loss: 4.9944e-04\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 7.5385e-04 - val_loss: 5.1471e-04\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 7.5343e-04 - val_loss: 4.9305e-04\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 7.5681e-04 - val_loss: 4.8931e-04\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.4253e-04 - val_loss: 5.5466e-04\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 7.3088e-04 - val_loss: 4.7226e-04\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 7.2143e-04 - val_loss: 4.7212e-04\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.0176e-04 - val_loss: 4.6208e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 7.3363e-04 - val_loss: 4.5780e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 7.2605e-04 - val_loss: 4.5577e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 7.0960e-04 - val_loss: 4.5990e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.0536e-04 - val_loss: 4.3973e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 7.0499e-04 - val_loss: 4.6461e-04\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.0375e-04 - val_loss: 4.8436e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.9850e-04 - val_loss: 4.4021e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.8245e-04 - val_loss: 4.8528e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 6.9574e-04 - val_loss: 4.3957e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.9825e-04 - val_loss: 4.3627e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.8005e-04 - val_loss: 4.3708e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.7199e-04 - val_loss: 4.3471e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 6.7878e-04 - val_loss: 4.2871e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.7746e-04 - val_loss: 4.4697e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 6.9048e-04 - val_loss: 4.8731e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.9740e-04 - val_loss: 4.1491e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.6205e-04 - val_loss: 4.4725e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.5755e-04 - val_loss: 4.5120e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.5391e-04 - val_loss: 4.0782e-04\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.6728e-04 - val_loss: 4.2374e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 6.5165e-04 - val_loss: 4.4899e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.4268e-04 - val_loss: 4.1094e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.4421e-04 - val_loss: 4.9705e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.5873e-04 - val_loss: 3.9593e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.4654e-04 - val_loss: 4.9417e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 6.3768e-04 - val_loss: 3.9671e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.2493e-04 - val_loss: 4.0158e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.4013e-04 - val_loss: 3.9608e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.3984e-04 - val_loss: 4.3513e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.4127e-04 - val_loss: 4.0440e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.3325e-04 - val_loss: 3.9907e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.4365e-04 - val_loss: 3.8808e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.2208e-04 - val_loss: 3.7202e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.1810e-04 - val_loss: 4.3819e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.1938e-04 - val_loss: 3.7025e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.1543e-04 - val_loss: 4.3993e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.1661e-04 - val_loss: 3.8206e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.1383e-04 - val_loss: 4.0809e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.0596e-04 - val_loss: 3.6329e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.1077e-04 - val_loss: 3.6166e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.0300e-04 - val_loss: 3.5877e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 6.1270e-04 - val_loss: 3.9482e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.0282e-04 - val_loss: 5.2817e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 5.9867e-04 - val_loss: 3.5984e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.0801e-04 - val_loss: 3.6436e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 5.9608e-04 - val_loss: 3.6854e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 5.9306e-04 - val_loss: 3.6644e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.1156e-04 - val_loss: 3.6761e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.8878e-04 - val_loss: 3.8011e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.8232e-04 - val_loss: 3.6295e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 5.7987e-04 - val_loss: 3.4525e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 5s 210us/step - loss: 5.8700e-04 - val_loss: 3.5417e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 7s 302us/step - loss: 5.8667e-04 - val_loss: 3.5652e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 5s 238us/step - loss: 5.9207e-04 - val_loss: 3.6533e-04\n",
      "Epoch 106/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 4s 183us/step - loss: 5.8106e-04 - val_loss: 3.6694e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 5.9195e-04 - val_loss: 3.6457e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 5.8349e-04 - val_loss: 4.2120e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 5.9452e-04 - val_loss: 3.7493e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 5.8212e-04 - val_loss: 3.8398e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 5.7681e-04 - val_loss: 3.5054e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 5.6353e-04 - val_loss: 3.6139e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 5.6588e-04 - val_loss: 3.4270e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 5.6972e-04 - val_loss: 3.3636e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 5.7547e-04 - val_loss: 3.7169e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 5.6273e-04 - val_loss: 3.8108e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 5.6570e-04 - val_loss: 3.7206e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 5.6281e-04 - val_loss: 3.6640e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 5.6738e-04 - val_loss: 3.4284e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 5.5773e-04 - val_loss: 3.5214e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 5.8024e-04 - val_loss: 3.3217e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 5.5956e-04 - val_loss: 3.4230e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 3s 145us/step - loss: 5.5635e-04 - val_loss: 3.6972e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.5697e-04 - val_loss: 3.3417e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.5955e-04 - val_loss: 3.2042e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.5798e-04 - val_loss: 3.3239e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.4912e-04 - val_loss: 3.2785e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.4821e-04 - val_loss: 3.3713e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.6024e-04 - val_loss: 3.3939e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.4845e-04 - val_loss: 3.3002e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.4596e-04 - val_loss: 3.2931e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.5447e-04 - val_loss: 3.3707e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.3870e-04 - val_loss: 3.3607e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.5395e-04 - val_loss: 3.1679e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.3643e-04 - val_loss: 3.5872e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.4900e-04 - val_loss: 3.2671e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.5412e-04 - val_loss: 3.1446e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.4438e-04 - val_loss: 3.0741e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.4435e-04 - val_loss: 3.4061e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.3786e-04 - val_loss: 3.3651e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.4193e-04 - val_loss: 3.3828e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 3s 146us/step - loss: 5.3692e-04 - val_loss: 3.1998e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.3342e-04 - val_loss: 3.6652e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.3536e-04 - val_loss: 3.1048e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.3649e-04 - val_loss: 3.0633e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.2173e-04 - val_loss: 3.1376e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.2881e-04 - val_loss: 3.0233e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.3853e-04 - val_loss: 3.1937e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.3976e-04 - val_loss: 3.2659e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.2631e-04 - val_loss: 3.1054e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.3175e-04 - val_loss: 3.3178e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.3009e-04 - val_loss: 3.0585e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.2417e-04 - val_loss: 3.1650e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.3833e-04 - val_loss: 3.1261e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.2647e-04 - val_loss: 3.1435e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.2340e-04 - val_loss: 3.0269e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.2451e-04 - val_loss: 3.0422e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1417e-04 - val_loss: 3.2793e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.2177e-04 - val_loss: 3.0753e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.0860e-04 - val_loss: 2.9308e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1605e-04 - val_loss: 2.9689e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1461e-04 - val_loss: 3.0115e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 5.0931e-04 - val_loss: 2.9566e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.1593e-04 - val_loss: 3.0323e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1946e-04 - val_loss: 3.0963e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1731e-04 - val_loss: 3.1790e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.0371e-04 - val_loss: 2.9385e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.0904e-04 - val_loss: 3.0915e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.2103e-04 - val_loss: 3.1470e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.9839e-04 - val_loss: 2.9925e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1119e-04 - val_loss: 3.1909e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.0252e-04 - val_loss: 3.0461e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.0760e-04 - val_loss: 3.5873e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.0247e-04 - val_loss: 3.0691e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.0520e-04 - val_loss: 2.9522e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.1484e-04 - val_loss: 3.3655e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.2268e-04 - val_loss: 3.3266e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1118e-04 - val_loss: 3.1642e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.2353e-04 - val_loss: 2.9653e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.9684e-04 - val_loss: 3.0282e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.0262e-04 - val_loss: 3.0116e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.0856e-04 - val_loss: 2.8300e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.9783e-04 - val_loss: 2.8408e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 4.9791e-04 - val_loss: 2.9995e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.1286e-04 - val_loss: 3.4566e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.9246e-04 - val_loss: 2.8106e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.0318e-04 - val_loss: 3.0474e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.8924e-04 - val_loss: 2.8126e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.0194e-04 - val_loss: 2.9828e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8969e-04 - val_loss: 2.7790e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.9573e-04 - val_loss: 3.0452e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 5.0064e-04 - val_loss: 2.8958e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.9815e-04 - val_loss: 2.8581e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8880e-04 - val_loss: 2.8843e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.0710e-04 - val_loss: 3.1360e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.0400e-04 - val_loss: 2.9459e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.9257e-04 - val_loss: 2.9715e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8457e-04 - val_loss: 2.7471e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.9086e-04 - val_loss: 3.0681e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8535e-04 - val_loss: 2.7706e-04\n",
      "6944/6944 [==============================] - 0s 38us/step\n",
      "Now processing station number 154\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 12s 526us/step - loss: 0.0079 - val_loss: 0.0023\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0014 - val_loss: 8.8409e-04\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0013 - val_loss: 8.9500e-04\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0012 - val_loss: 8.0695e-04\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0012 - val_loss: 7.9760e-04\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0011 - val_loss: 7.4457e-04\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 0.0012 - val_loss: 7.0796e-04\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0011 - val_loss: 7.2283e-04\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0011 - val_loss: 8.2757e-04\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0011 - val_loss: 6.9003e-04\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0010 - val_loss: 6.7899e-04\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0010 - val_loss: 6.4234e-04\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.7830e-04 - val_loss: 6.4304e-04\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.8021e-04 - val_loss: 5.9189e-04\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 9.5755e-04 - val_loss: 7.0223e-04\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 9.7802e-04 - val_loss: 6.4394e-04\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 9.2228e-04 - val_loss: 5.7662e-04\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.9490e-04 - val_loss: 5.7962e-04\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 9.5740e-04 - val_loss: 6.1604e-04\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.0992e-04 - val_loss: 6.6526e-04\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.8490e-04 - val_loss: 5.7858e-04\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 8.6082e-04 - val_loss: 5.8746e-04\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0402e-04 - val_loss: 5.4390e-04\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 8.8723e-04 - val_loss: 5.6572e-04\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 9.0082e-04 - val_loss: 5.4792e-04\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 8.9972e-04 - val_loss: 6.9544e-04\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.5393e-04 - val_loss: 5.7027e-04\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6974e-04 - val_loss: 5.6527e-04\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.1229e-04 - val_loss: 5.6120e-04\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.9936e-04 - val_loss: 5.4429e-04\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.8483e-04 - val_loss: 5.8236e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.3146e-04 - val_loss: 5.4257e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.7870e-04 - val_loss: 4.9709e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.6383e-04 - val_loss: 5.7518e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.7446e-04 - val_loss: 5.1768e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.7654e-04 - val_loss: 5.1949e-04\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.7874e-04 - val_loss: 4.7972e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.4856e-04 - val_loss: 4.7495e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.6812e-04 - val_loss: 5.2798e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.4555e-04 - val_loss: 5.2240e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.3758e-04 - val_loss: 5.1914e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.2741e-04 - val_loss: 5.0755e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.3418e-04 - val_loss: 4.7388e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.4021e-04 - val_loss: 4.8412e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.2861e-04 - val_loss: 4.5557e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.2351e-04 - val_loss: 4.5422e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.3883e-04 - val_loss: 4.5048e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.4367e-04 - val_loss: 5.4326e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.1472e-04 - val_loss: 4.2872e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.1476e-04 - val_loss: 4.5806e-04\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.2710e-04 - val_loss: 4.7992e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 7.1179e-04 - val_loss: 4.2903e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.9511e-04 - val_loss: 4.4472e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.9145e-04 - val_loss: 4.3822e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.1470e-04 - val_loss: 4.2142e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.0150e-04 - val_loss: 5.4094e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.0090e-04 - val_loss: 4.9274e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.6557e-04 - val_loss: 4.6818e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.6788e-04 - val_loss: 4.3494e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.6749e-04 - val_loss: 4.2759e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.7134e-04 - val_loss: 4.5840e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.6495e-04 - val_loss: 4.3786e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.6625e-04 - val_loss: 4.2406e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.4708e-04 - val_loss: 4.3103e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.5677e-04 - val_loss: 4.0624e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.5878e-04 - val_loss: 4.7338e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.8143e-04 - val_loss: 5.7239e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.8958e-04 - val_loss: 5.1848e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.5792e-04 - val_loss: 4.1392e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.5968e-04 - val_loss: 4.2686e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.6173e-04 - val_loss: 4.1543e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.3644e-04 - val_loss: 4.7588e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.6746e-04 - val_loss: 4.6522e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.4051e-04 - val_loss: 3.9236e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.3796e-04 - val_loss: 3.9025e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.3553e-04 - val_loss: 3.8015e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.3580e-04 - val_loss: 4.1538e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.4612e-04 - val_loss: 4.2713e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.3044e-04 - val_loss: 4.5056e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.4671e-04 - val_loss: 3.8273e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.0833e-04 - val_loss: 3.6863e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.1024e-04 - val_loss: 4.1133e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.4104e-04 - val_loss: 3.8985e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.0731e-04 - val_loss: 3.9066e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.5104e-04 - val_loss: 3.6696e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.1468e-04 - val_loss: 3.9071e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.9688e-04 - val_loss: 3.7006e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.2929e-04 - val_loss: 3.8900e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.0137e-04 - val_loss: 3.8177e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.0502e-04 - val_loss: 3.6573e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.9500e-04 - val_loss: 3.9617e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.8348e-04 - val_loss: 3.7284e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.8989e-04 - val_loss: 4.0517e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.8775e-04 - val_loss: 3.5205e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.0650e-04 - val_loss: 3.9227e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.9477e-04 - val_loss: 3.8402e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.8697e-04 - val_loss: 3.8645e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.6916e-04 - val_loss: 3.8522e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.7932e-04 - val_loss: 3.7133e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.6204e-04 - val_loss: 3.7116e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.8651e-04 - val_loss: 3.5556e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.7947e-04 - val_loss: 3.5224e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.5210e-04 - val_loss: 3.9075e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.7603e-04 - val_loss: 3.5397e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.0016e-04 - val_loss: 4.0984e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.7039e-04 - val_loss: 3.7123e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.5678e-04 - val_loss: 3.4733e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.6859e-04 - val_loss: 3.8680e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.7878e-04 - val_loss: 4.1602e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.6327e-04 - val_loss: 3.4629e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.6890e-04 - val_loss: 3.4591e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.4208e-04 - val_loss: 3.6572e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.5168e-04 - val_loss: 3.3576e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.4936e-04 - val_loss: 3.5196e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.9578e-04 - val_loss: 3.3591e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.5416e-04 - val_loss: 3.7882e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.5979e-04 - val_loss: 3.4440e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.5991e-04 - val_loss: 3.8071e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.5951e-04 - val_loss: 3.4597e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.2466e-04 - val_loss: 3.5544e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.6821e-04 - val_loss: 3.5425e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.3005e-04 - val_loss: 3.2654e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.5265e-04 - val_loss: 4.0783e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.5310e-04 - val_loss: 3.5625e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.3533e-04 - val_loss: 3.5877e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.2531e-04 - val_loss: 4.0067e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.2890e-04 - val_loss: 3.5050e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.3163e-04 - val_loss: 3.1924e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.4480e-04 - val_loss: 3.2755e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1814e-04 - val_loss: 4.0601e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.2829e-04 - val_loss: 3.6286e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1467e-04 - val_loss: 3.4448e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.2664e-04 - val_loss: 4.0656e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.4281e-04 - val_loss: 3.1996e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.1809e-04 - val_loss: 3.6678e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.2422e-04 - val_loss: 3.3975e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1748e-04 - val_loss: 3.4799e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.4326e-04 - val_loss: 3.4028e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.2058e-04 - val_loss: 3.1647e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.9691e-04 - val_loss: 4.1424e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.7694e-04 - val_loss: 3.6983e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.0309e-04 - val_loss: 3.5350e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.9947e-04 - val_loss: 3.3089e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.2452e-04 - val_loss: 3.0552e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.9162e-04 - val_loss: 3.2705e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.0482e-04 - val_loss: 3.7872e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.2290e-04 - val_loss: 3.2099e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 5.1383e-04 - val_loss: 3.5208e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.0088e-04 - val_loss: 3.1200e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.9974e-04 - val_loss: 3.3326e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.8763e-04 - val_loss: 3.0462e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.9352e-04 - val_loss: 3.5010e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.8728e-04 - val_loss: 3.1550e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.8822e-04 - val_loss: 3.8133e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 5.1945e-04 - val_loss: 3.0996e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.8672e-04 - val_loss: 3.3530e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1078e-04 - val_loss: 3.6645e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.0893e-04 - val_loss: 3.5705e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.7226e-04 - val_loss: 3.1987e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.9088e-04 - val_loss: 3.1449e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.0507e-04 - val_loss: 3.1212e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.6471e-04 - val_loss: 3.1610e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.7231e-04 - val_loss: 3.4093e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 4.6386e-04 - val_loss: 3.7622e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.1092e-04 - val_loss: 3.3400e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.0620e-04 - val_loss: 3.0408e-04\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8028e-04 - val_loss: 3.4744e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.7787e-04 - val_loss: 3.0720e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.2154e-04 - val_loss: 3.4096e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.8822e-04 - val_loss: 3.0336e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8577e-04 - val_loss: 3.0099e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.5698e-04 - val_loss: 3.0074e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.5420e-04 - val_loss: 3.1192e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 4.8741e-04 - val_loss: 3.1276e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.6277e-04 - val_loss: 3.0292e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.8245e-04 - val_loss: 3.4045e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.6889e-04 - val_loss: 3.0805e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 4.5358e-04 - val_loss: 3.0513e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 4.5137e-04 - val_loss: 3.2244e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.5613e-04 - val_loss: 3.2792e-04\n",
      "6944/6944 [==============================] - 0s 38us/step\n",
      "Now processing station number 155\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 12s 549us/step - loss: 0.0061 - val_loss: 0.0011\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0013 - val_loss: 8.4679e-04\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0012 - val_loss: 8.1880e-04\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0011 - val_loss: 7.8250e-04\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0011 - val_loss: 7.8302e-04\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0010 - val_loss: 7.5880e-04\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 0.0010 - val_loss: 7.6033e-04\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.8821e-04 - val_loss: 7.8691e-04\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.7098e-04 - val_loss: 7.4037e-04\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.6183e-04 - val_loss: 7.3466e-04\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.4745e-04 - val_loss: 7.2003e-04\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.3863e-04 - val_loss: 7.3790e-04\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 9.2094e-04 - val_loss: 7.2857e-04\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.1865e-04 - val_loss: 7.1019e-04\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 9.1101e-04 - val_loss: 7.2328e-04\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 9.2187e-04 - val_loss: 7.0465e-04\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.8204e-04 - val_loss: 7.8689e-04\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.8286e-04 - val_loss: 7.1498e-04\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 3s 147us/step - loss: 8.7970e-04 - val_loss: 6.9562e-04\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.6626e-04 - val_loss: 6.9654e-04\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.5457e-04 - val_loss: 6.7162e-04\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 8.3113e-04 - val_loss: 6.9291e-04\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 8.2890e-04 - val_loss: 6.6425e-04\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.0064e-04 - val_loss: 6.5268e-04\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 8.1034e-04 - val_loss: 6.8126e-04\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 8.0562e-04 - val_loss: 6.4621e-04\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 7.8779e-04 - val_loss: 6.4447e-04\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.9592e-04 - val_loss: 6.4645e-04\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.8241e-04 - val_loss: 6.4456e-04\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.8238e-04 - val_loss: 6.3551e-04\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.7443e-04 - val_loss: 6.4377e-04\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.7956e-04 - val_loss: 6.2805e-04\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.8046e-04 - val_loss: 6.2948e-04\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.5954e-04 - val_loss: 6.1764e-04\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.6469e-04 - val_loss: 6.3242e-04\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.4774e-04 - val_loss: 6.4073e-04\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.5264e-04 - val_loss: 6.2231e-04\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.5357e-04 - val_loss: 6.1491e-04\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.5217e-04 - val_loss: 6.4879e-04\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.4789e-04 - val_loss: 6.1667e-04\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.4330e-04 - val_loss: 6.0197e-04\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.2858e-04 - val_loss: 6.2512e-04\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.4786e-04 - val_loss: 6.6830e-04\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.2509e-04 - val_loss: 6.1193e-04\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 7.4633e-04 - val_loss: 5.9023e-04\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.3404e-04 - val_loss: 6.0067e-04\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 7.1846e-04 - val_loss: 5.9339e-04\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.2770e-04 - val_loss: 6.0494e-04\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.1659e-04 - val_loss: 5.9541e-04\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.1508e-04 - val_loss: 5.7701e-04\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.0261e-04 - val_loss: 5.6749e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 7.2184e-04 - val_loss: 5.7667e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 7.0509e-04 - val_loss: 5.4875e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.0461e-04 - val_loss: 5.5236e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.9216e-04 - val_loss: 5.4988e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 6.9273e-04 - val_loss: 5.4174e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.9009e-04 - val_loss: 5.4281e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.8460e-04 - val_loss: 5.5318e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.9616e-04 - val_loss: 5.6362e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.9261e-04 - val_loss: 5.4319e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 7.0460e-04 - val_loss: 5.5217e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.8231e-04 - val_loss: 6.2094e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 3s 148us/step - loss: 6.8526e-04 - val_loss: 5.6146e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.8085e-04 - val_loss: 5.3875e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.8682e-04 - val_loss: 6.4680e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 3s 149us/step - loss: 6.7773e-04 - val_loss: 5.8843e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.8524e-04 - val_loss: 5.3985e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.7031e-04 - val_loss: 5.3617e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 6.6969e-04 - val_loss: 5.4489e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 6.9414e-04 - val_loss: 5.3298e-04\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 6.5934e-04 - val_loss: 5.3185e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 6.8114e-04 - val_loss: 5.8674e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 5s 213us/step - loss: 6.8217e-04 - val_loss: 5.3889e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 6.7096e-04 - val_loss: 5.4867e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 6.7982e-04 - val_loss: 5.4134e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 6.6931e-04 - val_loss: 5.3795e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 7s 334us/step - loss: 6.7189e-04 - val_loss: 5.4420e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 5s 223us/step - loss: 6.7440e-04 - val_loss: 5.4356e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 5s 206us/step - loss: 6.8293e-04 - val_loss: 5.5386e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 6s 277us/step - loss: 6.6475e-04 - val_loss: 5.8126e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 6.6236e-04 - val_loss: 5.4062e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.6342e-04 - val_loss: 5.4341e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 6.6577e-04 - val_loss: 5.8399e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 5s 205us/step - loss: 6.6343e-04 - val_loss: 5.5491e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 6.6431e-04 - val_loss: 5.2842e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.6314e-04 - val_loss: 5.3477e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 6.6203e-04 - val_loss: 5.2860e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 5s 230us/step - loss: 6.6586e-04 - val_loss: 5.3144e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 6.6883e-04 - val_loss: 5.4702e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 5s 211us/step - loss: 6.6032e-04 - val_loss: 5.3479e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 7s 314us/step - loss: 6.6356e-04 - val_loss: 5.5726e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 3s 158us/step - loss: 6.6059e-04 - val_loss: 5.3621e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.7012e-04 - val_loss: 5.6635e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 6.5921e-04 - val_loss: 5.6743e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 6.6707e-04 - val_loss: 5.2882e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.5837e-04 - val_loss: 5.2266e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.5524e-04 - val_loss: 5.2463e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.5584e-04 - val_loss: 5.2781e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.5960e-04 - val_loss: 5.2758e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 6.6086e-04 - val_loss: 5.3475e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 6.5573e-04 - val_loss: 5.2788e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 6.6410e-04 - val_loss: 5.2323e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.5713e-04 - val_loss: 5.3107e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.5400e-04 - val_loss: 5.3197e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 6s 270us/step - loss: 6.5318e-04 - val_loss: 5.2770e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 5s 219us/step - loss: 6.4263e-04 - val_loss: 5.2291e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 6.4743e-04 - val_loss: 5.3901e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 7s 327us/step - loss: 6.6501e-04 - val_loss: 5.2295e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 6s 283us/step - loss: 6.5774e-04 - val_loss: 5.3253e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 6.5978e-04 - val_loss: 5.3180e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 6.4726e-04 - val_loss: 5.4018e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 6s 253us/step - loss: 6.4453e-04 - val_loss: 5.2767e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 5s 203us/step - loss: 6.5900e-04 - val_loss: 5.4468e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 5s 229us/step - loss: 6.5686e-04 - val_loss: 5.2678e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 5s 222us/step - loss: 6.4612e-04 - val_loss: 5.2675e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 6.4567e-04 - val_loss: 5.2820e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 5s 206us/step - loss: 6.4792e-04 - val_loss: 5.4144e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 6.5493e-04 - val_loss: 5.2158e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.4810e-04 - val_loss: 5.2506e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 6.5096e-04 - val_loss: 5.4495e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.5929e-04 - val_loss: 5.1478e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.4646e-04 - val_loss: 5.3625e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 6.4062e-04 - val_loss: 5.1908e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 6.3884e-04 - val_loss: 5.2328e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 6.5294e-04 - val_loss: 5.4542e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 6.4441e-04 - val_loss: 5.2128e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.4253e-04 - val_loss: 5.3215e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 6.3538e-04 - val_loss: 5.1736e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 6.4494e-04 - val_loss: 5.5462e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 6.4480e-04 - val_loss: 5.1979e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 6.3266e-04 - val_loss: 5.2066e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 6.4719e-04 - val_loss: 5.4679e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.3472e-04 - val_loss: 5.1572e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 6.3646e-04 - val_loss: 6.3656e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.3682e-04 - val_loss: 5.1164e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 6.3211e-04 - val_loss: 5.2903e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.3773e-04 - val_loss: 5.1483e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 4s 195us/step - loss: 6.4737e-04 - val_loss: 5.2311e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 6.2987e-04 - val_loss: 5.2637e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.3511e-04 - val_loss: 5.1346e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 6.3781e-04 - val_loss: 5.1543e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 6.2986e-04 - val_loss: 5.2647e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 6.3498e-04 - val_loss: 5.2397e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 6.2203e-04 - val_loss: 5.1852e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 6.2756e-04 - val_loss: 5.0927e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 6.2096e-04 - val_loss: 5.2999e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 6.2671e-04 - val_loss: 5.2060e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 6.3308e-04 - val_loss: 5.0534e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 6.1962e-04 - val_loss: 5.1473e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 6.2149e-04 - val_loss: 5.0916e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 6.0953e-04 - val_loss: 4.9920e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 5s 214us/step - loss: 6.3523e-04 - val_loss: 5.0302e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.0712e-04 - val_loss: 5.0012e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.1329e-04 - val_loss: 5.0019e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 6.0812e-04 - val_loss: 5.0305e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 6.1063e-04 - val_loss: 5.1638e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 6.0857e-04 - val_loss: 4.9264e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.0297e-04 - val_loss: 5.0943e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.0839e-04 - val_loss: 4.8956e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 5.9595e-04 - val_loss: 5.2069e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 6.1302e-04 - val_loss: 4.9494e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 5.9096e-04 - val_loss: 4.8172e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 5.9024e-04 - val_loss: 4.8452e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 5.8613e-04 - val_loss: 4.8409e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 5.8847e-04 - val_loss: 4.9222e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 5.7815e-04 - val_loss: 4.9446e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 5.8063e-04 - val_loss: 4.7859e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 5.7041e-04 - val_loss: 4.6824e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 5.6777e-04 - val_loss: 4.7760e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 5.8276e-04 - val_loss: 4.7238e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 5.7525e-04 - val_loss: 4.7797e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 5.7234e-04 - val_loss: 4.7166e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.7078e-04 - val_loss: 4.9269e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 5.7096e-04 - val_loss: 4.7024e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 5.6475e-04 - val_loss: 4.5964e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 5.6645e-04 - val_loss: 4.6332e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 5.5883e-04 - val_loss: 4.5654e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 5.7040e-04 - val_loss: 4.5552e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.5864e-04 - val_loss: 4.7480e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 5.5687e-04 - val_loss: 4.5032e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 5.5184e-04 - val_loss: 4.5207e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 5.5967e-04 - val_loss: 4.5348e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 5.4987e-04 - val_loss: 4.9752e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 7s 293us/step - loss: 5.4663e-04 - val_loss: 4.4714e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 5.5187e-04 - val_loss: 4.6385e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.5244e-04 - val_loss: 4.4234e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 5.4417e-04 - val_loss: 4.4037e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 5.4323e-04 - val_loss: 4.5165e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 5.3803e-04 - val_loss: 4.3952e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 5.3718e-04 - val_loss: 4.7305e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 5.3785e-04 - val_loss: 4.4434e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 5.2613e-04 - val_loss: 4.3463e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 5.3410e-04 - val_loss: 4.6736e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 5.2930e-04 - val_loss: 4.4618e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.3195e-04 - val_loss: 4.3315e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 5.2714e-04 - val_loss: 4.2458e-04\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 4s 173us/step - loss: 5.2427e-04 - val_loss: 4.4626e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 5.2268e-04 - val_loss: 4.2459e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 5.1805e-04 - val_loss: 4.2613e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.1653e-04 - val_loss: 4.8185e-04\n",
      "6944/6944 [==============================] - 0s 38us/step\n",
      "Now processing station number 156\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 15s 666us/step - loss: 0.0128 - val_loss: 0.0040\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 4s 191us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 4s 195us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 5s 222us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 6s 267us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 6s 256us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 4s 175us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 5s 204us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 5s 203us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 4s 195us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 5s 220us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 5s 210us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 8s 344us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 5s 221us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 5s 218us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 5s 234us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 7s 318us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 5s 238us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 6s 279us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 6s 276us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 6s 252us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 5s 239us/step - loss: 0.0016 - val_loss: 9.9686e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 5s 210us/step - loss: 0.0016 - val_loss: 9.5319e-04\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 0.0015 - val_loss: 9.2577e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 0.0015 - val_loss: 9.4969e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0016 - val_loss: 9.3529e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 0.0015 - val_loss: 9.5472e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 0.0015 - val_loss: 9.2312e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 0.0015 - val_loss: 9.6201e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 0.0015 - val_loss: 9.0106e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 5s 222us/step - loss: 0.0014 - val_loss: 9.5798e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 0.0015 - val_loss: 9.2322e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 7s 319us/step - loss: 0.0014 - val_loss: 8.8212e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0014 - val_loss: 8.6163e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0015 - val_loss: 8.5143e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 0.0014 - val_loss: 8.9043e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 0.0014 - val_loss: 9.1094e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 5s 224us/step - loss: 0.0014 - val_loss: 8.8889e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 4s 202us/step - loss: 0.0014 - val_loss: 8.6360e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 0.0013 - val_loss: 8.3053e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 6s 249us/step - loss: 0.0013 - val_loss: 8.1197e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 6s 276us/step - loss: 0.0013 - val_loss: 8.0971e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 5s 243us/step - loss: 0.0013 - val_loss: 8.4884e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 0.0013 - val_loss: 7.9974e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 0.0013 - val_loss: 7.8878e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 0.0014 - val_loss: 8.5178e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 0.0013 - val_loss: 8.0971e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 0.0013 - val_loss: 7.8857e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 4s 189us/step - loss: 0.0013 - val_loss: 7.7694e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 0.0013 - val_loss: 8.1484e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 0.0013 - val_loss: 7.1971e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0012 - val_loss: 7.2161e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 0.0012 - val_loss: 7.9218e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0012 - val_loss: 7.6773e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0012 - val_loss: 7.1622e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 0.0012 - val_loss: 7.3985e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0012 - val_loss: 6.7205e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 5s 221us/step - loss: 0.0012 - val_loss: 6.8316e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 6s 250us/step - loss: 0.0012 - val_loss: 7.3495e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 7s 306us/step - loss: 0.0012 - val_loss: 6.9305e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 5s 215us/step - loss: 0.0012 - val_loss: 7.0717e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 0.0012 - val_loss: 7.1514e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 0.0012 - val_loss: 6.5178e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 0.0011 - val_loss: 6.6813e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 0.0012 - val_loss: 6.3868e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 7s 311us/step - loss: 0.0011 - val_loss: 6.6739e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 5s 243us/step - loss: 0.0011 - val_loss: 6.5299e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 5s 239us/step - loss: 0.0011 - val_loss: 6.3338e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 5s 238us/step - loss: 0.0011 - val_loss: 7.1111e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 5s 212us/step - loss: 0.0011 - val_loss: 6.5796e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 5s 203us/step - loss: 0.0011 - val_loss: 6.5388e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 0.0011 - val_loss: 6.2084e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 4s 196us/step - loss: 0.0011 - val_loss: 6.3235e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 0.0011 - val_loss: 6.0382e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 0.0011 - val_loss: 6.0944e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 0.0011 - val_loss: 6.4482e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 0.0011 - val_loss: 6.8096e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 0.0011 - val_loss: 5.9297e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 5s 219us/step - loss: 0.0010 - val_loss: 5.8370e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 6s 249us/step - loss: 0.0010 - val_loss: 6.1296e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 5s 236us/step - loss: 0.0011 - val_loss: 6.8091e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 5s 232us/step - loss: 0.0010 - val_loss: 6.1855e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 5s 236us/step - loss: 0.0010 - val_loss: 6.0086e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 5s 217us/step - loss: 0.0010 - val_loss: 5.5591e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 5s 208us/step - loss: 0.0010 - val_loss: 5.7875e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 4s 198us/step - loss: 0.0010 - val_loss: 6.0302e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 6s 290us/step - loss: 0.0010 - val_loss: 5.9290e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 6s 274us/step - loss: 0.0010 - val_loss: 6.4207e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 0.0011 - val_loss: 5.6235e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 0.0010 - val_loss: 6.3147e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 0.0010 - val_loss: 6.5084e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0010 - val_loss: 5.6758e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0010 - val_loss: 8.2340e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 0.0011 - val_loss: 5.9099e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 0.0010 - val_loss: 6.1832e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 9.8459e-04 - val_loss: 5.8410e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 0.0010 - val_loss: 5.9853e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 9.8368e-04 - val_loss: 5.9199e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 9.6063e-04 - val_loss: 5.5596e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 9.7362e-04 - val_loss: 5.7709e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 9.5153e-04 - val_loss: 6.8433e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 9.7363e-04 - val_loss: 6.6237e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 9.9768e-04 - val_loss: 5.5780e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 9.7974e-04 - val_loss: 5.6868e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 9.3966e-04 - val_loss: 5.6090e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 9.6353e-04 - val_loss: 6.2283e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 9.4887e-04 - val_loss: 5.6716e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 5s 217us/step - loss: 9.4480e-04 - val_loss: 5.8372e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 4s 202us/step - loss: 9.3358e-04 - val_loss: 5.6777e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 9.3324e-04 - val_loss: 5.2984e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 9.4894e-04 - val_loss: 5.5561e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 4s 193us/step - loss: 9.0951e-04 - val_loss: 5.7840e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 5s 213us/step - loss: 9.1362e-04 - val_loss: 5.2130e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 6s 262us/step - loss: 9.2610e-04 - val_loss: 5.5795e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 9.1928e-04 - val_loss: 5.9102e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 5s 212us/step - loss: 9.2556e-04 - val_loss: 5.4731e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 5s 233us/step - loss: 9.3184e-04 - val_loss: 6.6077e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 5s 218us/step - loss: 9.2493e-04 - val_loss: 5.5350e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 8.9735e-04 - val_loss: 5.8126e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 8s 339us/step - loss: 8.9543e-04 - val_loss: 5.4831e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 5s 221us/step - loss: 8.8893e-04 - val_loss: 5.5466e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 5s 216us/step - loss: 8.9490e-04 - val_loss: 5.4851e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 8.8929e-04 - val_loss: 5.1717e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 5s 206us/step - loss: 9.0890e-04 - val_loss: 5.6423e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 5s 230us/step - loss: 8.8297e-04 - val_loss: 5.2724e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.7628e-04 - val_loss: 5.1103e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 8.8134e-04 - val_loss: 6.9473e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 5s 216us/step - loss: 8.8945e-04 - val_loss: 5.3751e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 4s 177us/step - loss: 8.7518e-04 - val_loss: 5.1763e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 6s 248us/step - loss: 8.8310e-04 - val_loss: 5.7261e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 6s 259us/step - loss: 9.0148e-04 - val_loss: 5.0940e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 8s 357us/step - loss: 8.6468e-04 - val_loss: 5.3121e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 6s 287us/step - loss: 8.4530e-04 - val_loss: 5.3311e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 5s 212us/step - loss: 8.6067e-04 - val_loss: 5.6330e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 8.4783e-04 - val_loss: 5.1185e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 8.4036e-04 - val_loss: 5.3985e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 8.5533e-04 - val_loss: 5.9181e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 8.4777e-04 - val_loss: 4.9276e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 8.6838e-04 - val_loss: 5.1268e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 8.6530e-04 - val_loss: 5.1552e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 8.4352e-04 - val_loss: 5.2333e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 8.3271e-04 - val_loss: 5.4941e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 8.4775e-04 - val_loss: 5.0088e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 8.3792e-04 - val_loss: 5.2299e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 8.3100e-04 - val_loss: 5.2390e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 8.3128e-04 - val_loss: 5.1665e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 8.0812e-04 - val_loss: 5.1369e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 7s 297us/step - loss: 8.1425e-04 - val_loss: 5.0282e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 5s 245us/step - loss: 8.2840e-04 - val_loss: 5.5594e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 7s 295us/step - loss: 8.5093e-04 - val_loss: 5.6888e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 6s 264us/step - loss: 8.1424e-04 - val_loss: 5.1856e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 5s 241us/step - loss: 8.1860e-04 - val_loss: 5.2443e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 4s 196us/step - loss: 8.2909e-04 - val_loss: 5.2619e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 6s 249us/step - loss: 8.3121e-04 - val_loss: 5.1665e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 8.1929e-04 - val_loss: 4.9825e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 7.9146e-04 - val_loss: 5.1610e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 7.9092e-04 - val_loss: 5.2731e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 5s 216us/step - loss: 8.0448e-04 - val_loss: 5.7597e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 5s 216us/step - loss: 7.9527e-04 - val_loss: 4.9685e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 5s 223us/step - loss: 8.3444e-04 - val_loss: 5.2983e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 9s 384us/step - loss: 7.8191e-04 - val_loss: 5.2400e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 8.0450e-04 - val_loss: 4.8927e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 7.8632e-04 - val_loss: 4.8832e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 8.0114e-04 - val_loss: 4.9869e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 5s 217us/step - loss: 7.7094e-04 - val_loss: 5.0602e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 7.7777e-04 - val_loss: 4.8663e-04\n",
      "6944/6944 [==============================] - 0s 38us/step\n",
      "Now processing station number 157\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 14s 631us/step - loss: 4.2134e-04 - val_loss: 7.7691e-05\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 8.6742e-05 - val_loss: 7.3049e-05\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 7.9748e-05 - val_loss: 6.6279e-05\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 7.7280e-05 - val_loss: 6.1700e-05\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 7.4858e-05 - val_loss: 6.1484e-05\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 7.3220e-05 - val_loss: 6.0347e-05\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 7.2315e-05 - val_loss: 6.3087e-05\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 7.1327e-05 - val_loss: 5.7837e-05\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.8356e-05 - val_loss: 5.7446e-05\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.9527e-05 - val_loss: 6.1892e-05\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 6.8320e-05 - val_loss: 5.6697e-05\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.6712e-05 - val_loss: 5.8011e-05\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 6.6200e-05 - val_loss: 6.1931e-05\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 6.8866e-05 - val_loss: 5.6174e-05\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 6.7564e-05 - val_loss: 6.1150e-05\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 6.5775e-05 - val_loss: 5.5630e-05\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 6.5220e-05 - val_loss: 5.6900e-05\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 6.6466e-05 - val_loss: 5.4878e-05\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.5414e-05 - val_loss: 5.6107e-05\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.4710e-05 - val_loss: 5.6202e-05\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 6.5676e-05 - val_loss: 5.6113e-05\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.7136e-05 - val_loss: 5.5497e-05\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.4282e-05 - val_loss: 5.4693e-05\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 6.5397e-05 - val_loss: 5.5485e-05\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 6.3098e-05 - val_loss: 5.4646e-05\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 6.3469e-05 - val_loss: 5.4533e-05\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.4171e-05 - val_loss: 5.4287e-05\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.4429e-05 - val_loss: 5.5015e-05\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.3587e-05 - val_loss: 5.8273e-05\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.2775e-05 - val_loss: 5.6610e-05\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.2108e-05 - val_loss: 5.6428e-05\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.2759e-05 - val_loss: 5.2303e-05\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 6.2201e-05 - val_loss: 5.3231e-05\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 6.3156e-05 - val_loss: 5.2380e-05\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.2850e-05 - val_loss: 5.2387e-05\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.1697e-05 - val_loss: 5.1550e-05\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.1776e-05 - val_loss: 5.1832e-05\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.1945e-05 - val_loss: 5.1429e-05\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.1956e-05 - val_loss: 5.2000e-05\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.3199e-05 - val_loss: 5.2498e-05\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.2252e-05 - val_loss: 5.1694e-05\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.2425e-05 - val_loss: 5.3017e-05\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.1261e-05 - val_loss: 5.1948e-05\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.1358e-05 - val_loss: 5.3950e-05\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.2853e-05 - val_loss: 5.6578e-05\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.1196e-05 - val_loss: 5.0796e-05\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.0791e-05 - val_loss: 5.2169e-05\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.1484e-05 - val_loss: 5.1265e-05\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.2075e-05 - val_loss: 5.0685e-05\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.1345e-05 - val_loss: 5.0810e-05\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 6.1239e-05 - val_loss: 5.5941e-05\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.0686e-05 - val_loss: 5.5095e-05\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 6.0980e-05 - val_loss: 5.3673e-05\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.0104e-05 - val_loss: 5.1324e-05\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 6.3089e-05 - val_loss: 5.0226e-05\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.9962e-05 - val_loss: 5.0095e-05\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.9771e-05 - val_loss: 5.2429e-05\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 6.0072e-05 - val_loss: 4.9808e-05\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.0261e-05 - val_loss: 5.0105e-05\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 5.9899e-05 - val_loss: 5.1214e-05\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 6.0612e-05 - val_loss: 5.1954e-05\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.9534e-05 - val_loss: 5.0852e-05\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.0039e-05 - val_loss: 4.9599e-05\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.9525e-05 - val_loss: 5.0526e-05\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.9683e-05 - val_loss: 5.0445e-05\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.9638e-05 - val_loss: 5.0337e-05\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.9606e-05 - val_loss: 4.9201e-05\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.9774e-05 - val_loss: 4.9712e-05\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 6.0008e-05 - val_loss: 5.2749e-05\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.8753e-05 - val_loss: 5.0386e-05\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 6.1019e-05 - val_loss: 6.4639e-05\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 7s 334us/step - loss: 6.0463e-05 - val_loss: 5.1025e-05\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 5s 240us/step - loss: 5.9225e-05 - val_loss: 4.8974e-05\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 6s 268us/step - loss: 5.9488e-05 - val_loss: 5.4956e-05\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 6s 253us/step - loss: 5.9496e-05 - val_loss: 4.9248e-05\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 5s 238us/step - loss: 5.9270e-05 - val_loss: 4.8687e-05\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 5s 237us/step - loss: 5.9076e-05 - val_loss: 4.9283e-05\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 5s 222us/step - loss: 5.9680e-05 - val_loss: 5.1912e-05\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 5.9180e-05 - val_loss: 4.9152e-05\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 4s 194us/step - loss: 5.9017e-05 - val_loss: 5.1245e-05\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 5.8661e-05 - val_loss: 4.8973e-05\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 5.8402e-05 - val_loss: 4.9243e-05\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 5.7938e-05 - val_loss: 4.9339e-05\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 5.8511e-05 - val_loss: 5.1584e-05\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 8s 375us/step - loss: 5.8903e-05 - val_loss: 4.9238e-05\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 5s 236us/step - loss: 5.8003e-05 - val_loss: 4.8748e-05\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 5s 218us/step - loss: 5.9223e-05 - val_loss: 5.8681e-05\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 5.8426e-05 - val_loss: 5.0106e-05\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 5.8126e-05 - val_loss: 4.9605e-05\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 8s 372us/step - loss: 5.8761e-05 - val_loss: 4.7623e-05\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 5s 214us/step - loss: 5.7978e-05 - val_loss: 4.9268e-05\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 9s 388us/step - loss: 5.8674e-05 - val_loss: 5.1601e-05\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 5s 212us/step - loss: 5.8627e-05 - val_loss: 4.7590e-05\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 5s 212us/step - loss: 5.7592e-05 - val_loss: 5.0359e-05\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 6s 259us/step - loss: 5.7609e-05 - val_loss: 4.8472e-05\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 5s 239us/step - loss: 5.8433e-05 - val_loss: 5.1603e-05\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 5s 224us/step - loss: 5.8407e-05 - val_loss: 4.8928e-05\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 5.7355e-05 - val_loss: 4.8106e-05\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 5.7722e-05 - val_loss: 4.8714e-05\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 5.7710e-05 - val_loss: 5.1621e-05\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 5.7651e-05 - val_loss: 4.7673e-05\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 5.8005e-05 - val_loss: 4.6939e-05\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 5.6367e-05 - val_loss: 4.7004e-05\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 5.7780e-05 - val_loss: 4.7374e-05\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.7067e-05 - val_loss: 4.6437e-05\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 5.7814e-05 - val_loss: 4.7222e-05\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 5.6228e-05 - val_loss: 4.7654e-05\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.6875e-05 - val_loss: 4.7356e-05\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 5.6896e-05 - val_loss: 4.6251e-05\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 5.6317e-05 - val_loss: 4.7759e-05\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 5.6875e-05 - val_loss: 5.5792e-05\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 5.6640e-05 - val_loss: 4.7793e-05\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 5.5630e-05 - val_loss: 4.6891e-05\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.6325e-05 - val_loss: 4.6573e-05\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.5837e-05 - val_loss: 4.7817e-05\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.5303e-05 - val_loss: 4.5070e-05\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 5.5464e-05 - val_loss: 4.4975e-05\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.6409e-05 - val_loss: 4.5065e-05\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.5153e-05 - val_loss: 4.5285e-05\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.4295e-05 - val_loss: 4.6769e-05\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.4660e-05 - val_loss: 4.4585e-05\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.4831e-05 - val_loss: 4.8601e-05\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.4970e-05 - val_loss: 4.6243e-05\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.4429e-05 - val_loss: 4.3449e-05\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.5241e-05 - val_loss: 4.4577e-05\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.3596e-05 - val_loss: 4.2167e-05\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.2726e-05 - val_loss: 4.2851e-05\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 5.3294e-05 - val_loss: 4.2046e-05\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 5.3716e-05 - val_loss: 4.1352e-05\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 5s 224us/step - loss: 5.2849e-05 - val_loss: 4.1175e-05\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 5s 235us/step - loss: 5.2474e-05 - val_loss: 4.3741e-05\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 5s 226us/step - loss: 5.2175e-05 - val_loss: 4.4734e-05\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 5s 234us/step - loss: 5.2255e-05 - val_loss: 4.2626e-05\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 4s 189us/step - loss: 5.1199e-05 - val_loss: 4.1175e-05\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 4s 176us/step - loss: 5.3467e-05 - val_loss: 4.6317e-05\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 5.1785e-05 - val_loss: 4.0655e-05\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 5.1083e-05 - val_loss: 4.3869e-05\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 5.0646e-05 - val_loss: 3.9400e-05\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 5.0452e-05 - val_loss: 4.0179e-05\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 4s 169us/step - loss: 5.0371e-05 - val_loss: 3.8929e-05\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 4.9437e-05 - val_loss: 3.9362e-05\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 5.0099e-05 - val_loss: 3.8255e-05\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 4.8760e-05 - val_loss: 3.8868e-05\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 4s 171us/step - loss: 5.0731e-05 - val_loss: 3.7576e-05\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 4s 164us/step - loss: 4.8801e-05 - val_loss: 3.7634e-05\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 4.8404e-05 - val_loss: 3.6918e-05\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 4.9715e-05 - val_loss: 4.3227e-05\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 5s 208us/step - loss: 4.8682e-05 - val_loss: 3.8202e-05\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 4.7909e-05 - val_loss: 3.6478e-05\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 4.7575e-05 - val_loss: 3.6571e-05\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 4s 170us/step - loss: 4.7632e-05 - val_loss: 3.5268e-05\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 4s 158us/step - loss: 4.8636e-05 - val_loss: 3.6487e-05\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 4s 172us/step - loss: 4.6373e-05 - val_loss: 3.6194e-05\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.6270e-05 - val_loss: 3.6531e-05\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 4s 166us/step - loss: 4.6187e-05 - val_loss: 3.6257e-05\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 4.5962e-05 - val_loss: 3.6187e-05\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 4.5201e-05 - val_loss: 3.5341e-05\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.5358e-05 - val_loss: 3.5414e-05\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.5350e-05 - val_loss: 3.3387e-05\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 4s 168us/step - loss: 4.5723e-05 - val_loss: 3.7008e-05\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 4.5079e-05 - val_loss: 3.2933e-05\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 4.5376e-05 - val_loss: 3.3584e-05\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 4s 162us/step - loss: 4.3965e-05 - val_loss: 3.3183e-05\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 4.4032e-05 - val_loss: 3.4429e-05\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 4s 165us/step - loss: 4.3816e-05 - val_loss: 3.1482e-05\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 4.4213e-05 - val_loss: 3.2148e-05\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 4s 163us/step - loss: 4.3824e-05 - val_loss: 3.1617e-05\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 4.3497e-05 - val_loss: 3.1580e-05\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2363e-05 - val_loss: 3.2434e-05\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2437e-05 - val_loss: 3.0466e-05\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2833e-05 - val_loss: 3.0868e-05\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 4s 173us/step - loss: 4.3242e-05 - val_loss: 3.1610e-05\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.2023e-05 - val_loss: 3.0280e-05\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.2077e-05 - val_loss: 2.9929e-05\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 4.1680e-05 - val_loss: 3.1289e-05\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.1481e-05 - val_loss: 3.0213e-05\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 4.1145e-05 - val_loss: 3.0545e-05\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.1192e-05 - val_loss: 3.0024e-05\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.1130e-05 - val_loss: 3.1735e-05\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.1171e-05 - val_loss: 2.9247e-05\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.1051e-05 - val_loss: 2.8699e-05\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.0599e-05 - val_loss: 3.5997e-05\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.1389e-05 - val_loss: 2.9468e-05\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.0065e-05 - val_loss: 2.8151e-05\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.0702e-05 - val_loss: 2.9129e-05\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.0513e-05 - val_loss: 3.0711e-05\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.0060e-05 - val_loss: 2.9398e-05\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 3.9523e-05 - val_loss: 2.7343e-05\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.0036e-05 - val_loss: 2.8106e-05\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 3.9874e-05 - val_loss: 2.7534e-05\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 3.9633e-05 - val_loss: 2.9111e-05\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 3.9364e-05 - val_loss: 2.7707e-05\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 3.9582e-05 - val_loss: 2.9239e-05\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 3.9199e-05 - val_loss: 2.7210e-05\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 4s 167us/step - loss: 3.9138e-05 - val_loss: 3.1736e-05\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 4s 159us/step - loss: 3.9131e-05 - val_loss: 2.8858e-05\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 3.8094e-05 - val_loss: 2.8079e-05\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 4s 161us/step - loss: 3.8420e-05 - val_loss: 2.7988e-05\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 3.8624e-05 - val_loss: 2.6716e-05\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 4s 174us/step - loss: 3.7609e-05 - val_loss: 2.5729e-05\n",
      "6944/6944 [==============================] - 0s 44us/step\n",
      "Now processing station number 158\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 16s 698us/step - loss: 0.0083 - val_loss: 0.0016\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 4s 191us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 5s 218us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 4s 185us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 4s 195us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 4s 202us/step - loss: 0.0015 - val_loss: 9.9689e-04\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0014 - val_loss: 9.7135e-04\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0014 - val_loss: 9.6904e-04\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0014 - val_loss: 9.4086e-04\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0014 - val_loss: 9.7183e-04\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0013 - val_loss: 9.1000e-04\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0012 - val_loss: 9.6888e-04\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0013 - val_loss: 9.8622e-04\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0012 - val_loss: 8.8301e-04\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0012 - val_loss: 8.1707e-04\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 4s 179us/step - loss: 0.0012 - val_loss: 8.9397e-04\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 0.0011 - val_loss: 8.4705e-04\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0011 - val_loss: 7.8363e-04\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 0.0011 - val_loss: 7.8977e-04\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 4s 160us/step - loss: 0.0011 - val_loss: 7.5675e-04\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 7.4849e-04\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 150us/step - loss: 0.0011 - val_loss: 7.1850e-04\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0011 - val_loss: 8.2196e-04\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0010 - val_loss: 7.3391e-04\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 8.5324e-04\n",
      "Epoch 34/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0010 - val_loss: 7.6168e-04\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0010 - val_loss: 6.9228e-04\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 151us/step - loss: 9.8521e-04 - val_loss: 6.9726e-04\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 9.8177e-04 - val_loss: 6.7532e-04\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 9.6857e-04 - val_loss: 6.7393e-04\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 6s 261us/step - loss: 9.4745e-04 - val_loss: 7.8327e-04\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 5s 227us/step - loss: 9.5294e-04 - val_loss: 6.8017e-04\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 5s 210us/step - loss: 9.1132e-04 - val_loss: 7.2820e-04\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 5s 216us/step - loss: 9.1209e-04 - val_loss: 6.4782e-04\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 5s 211us/step - loss: 9.1522e-04 - val_loss: 6.5672e-04\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 9.1069e-04 - val_loss: 6.9378e-04\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 8.9365e-04 - val_loss: 6.8674e-04\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 8.8529e-04 - val_loss: 6.5529e-04\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 8.7653e-04 - val_loss: 7.1286e-04\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 4s 186us/step - loss: 9.0029e-04 - val_loss: 6.3274e-04\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 4s 183us/step - loss: 8.7995e-04 - val_loss: 6.1741e-04\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 4s 180us/step - loss: 8.7609e-04 - val_loss: 6.3396e-04\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 8.5122e-04 - val_loss: 6.7078e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 8.3508e-04 - val_loss: 6.5870e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 4s 181us/step - loss: 8.3671e-04 - val_loss: 6.1460e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 4s 182us/step - loss: 8.3608e-04 - val_loss: 6.1642e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 8.2966e-04 - val_loss: 6.0531e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 7s 337us/step - loss: 8.4119e-04 - val_loss: 6.0990e-04\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 5s 247us/step - loss: 8.1832e-04 - val_loss: 6.0454e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 5s 226us/step - loss: 8.1737e-04 - val_loss: 5.9142e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 5s 206us/step - loss: 8.2383e-04 - val_loss: 5.9882e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 4s 201us/step - loss: 8.0537e-04 - val_loss: 6.1507e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 5s 208us/step - loss: 7.9804e-04 - val_loss: 5.9161e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 5s 204us/step - loss: 7.8763e-04 - val_loss: 5.8121e-04\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 5s 208us/step - loss: 7.7839e-04 - val_loss: 6.0478e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 4s 199us/step - loss: 7.6376e-04 - val_loss: 5.6193e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 5s 207us/step - loss: 7.6538e-04 - val_loss: 5.8014e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 4s 202us/step - loss: 7.6752e-04 - val_loss: 6.4626e-04\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 5s 205us/step - loss: 7.4244e-04 - val_loss: 5.4566e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 5s 208us/step - loss: 7.3995e-04 - val_loss: 5.4300e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 4s 200us/step - loss: 7.2256e-04 - val_loss: 6.2241e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 5s 203us/step - loss: 7.2976e-04 - val_loss: 5.3174e-04\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 5s 204us/step - loss: 7.0657e-04 - val_loss: 5.4231e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 5s 205us/step - loss: 7.1238e-04 - val_loss: 5.2880e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 5s 223us/step - loss: 6.9807e-04 - val_loss: 5.2025e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 5s 247us/step - loss: 6.8997e-04 - val_loss: 4.8483e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 5s 227us/step - loss: 6.7071e-04 - val_loss: 4.9764e-04\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 5s 219us/step - loss: 6.7481e-04 - val_loss: 5.1666e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 5s 221us/step - loss: 6.6423e-04 - val_loss: 4.7008e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 4s 194us/step - loss: 6.4748e-04 - val_loss: 4.5408e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 6.6134e-04 - val_loss: 4.9079e-04\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 6.4270e-04 - val_loss: 4.5489e-04\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 4s 189us/step - loss: 6.3310e-04 - val_loss: 4.7370e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 6.2311e-04 - val_loss: 4.7701e-04\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 6.2468e-04 - val_loss: 5.0144e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 6.0950e-04 - val_loss: 4.6383e-04\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 4s 190us/step - loss: 6.0041e-04 - val_loss: 4.2165e-04\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 4s 187us/step - loss: 6.0670e-04 - val_loss: 4.4065e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 4s 192us/step - loss: 5.8414e-04 - val_loss: 4.0354e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 5.9534e-04 - val_loss: 4.2205e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.7977e-04 - val_loss: 4.0810e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.6577e-04 - val_loss: 3.9663e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.6513e-04 - val_loss: 3.9053e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.4774e-04 - val_loss: 4.2234e-04\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.7168e-04 - val_loss: 3.8962e-04\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.4653e-04 - val_loss: 3.7618e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.5814e-04 - val_loss: 3.9337e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.3920e-04 - val_loss: 3.7734e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.4115e-04 - val_loss: 3.7098e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.3535e-04 - val_loss: 4.3588e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.4236e-04 - val_loss: 3.8621e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.2889e-04 - val_loss: 3.7559e-04\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.2972e-04 - val_loss: 3.8959e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.3059e-04 - val_loss: 3.9172e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.3362e-04 - val_loss: 4.3821e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.2562e-04 - val_loss: 3.7817e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.0552e-04 - val_loss: 3.6375e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.1670e-04 - val_loss: 3.5477e-04\n",
      "Epoch 107/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.2722e-04 - val_loss: 3.6778e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 5.0612e-04 - val_loss: 3.9640e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 5.0306e-04 - val_loss: 3.7774e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.9845e-04 - val_loss: 3.4066e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 5.0267e-04 - val_loss: 3.7138e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.8862e-04 - val_loss: 3.5913e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.9436e-04 - val_loss: 3.4687e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.8618e-04 - val_loss: 3.3373e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.8899e-04 - val_loss: 3.6811e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.8879e-04 - val_loss: 3.3517e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.7833e-04 - val_loss: 3.5104e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.7597e-04 - val_loss: 3.6835e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.7373e-04 - val_loss: 3.5017e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.6773e-04 - val_loss: 3.4949e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.7387e-04 - val_loss: 3.3872e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.7717e-04 - val_loss: 3.5277e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.7093e-04 - val_loss: 3.3410e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.7151e-04 - val_loss: 3.1513e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.7151e-04 - val_loss: 3.5904e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.6082e-04 - val_loss: 3.3466e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.6672e-04 - val_loss: 3.3108e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.5425e-04 - val_loss: 3.1150e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.4998e-04 - val_loss: 3.3221e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.6020e-04 - val_loss: 3.2808e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.6620e-04 - val_loss: 3.1900e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 4.5263e-04 - val_loss: 3.2054e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.5155e-04 - val_loss: 3.3247e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.5053e-04 - val_loss: 3.1772e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3909e-04 - val_loss: 3.2295e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.3909e-04 - val_loss: 3.2269e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.5374e-04 - val_loss: 3.3672e-04\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.5794e-04 - val_loss: 3.0388e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.3934e-04 - val_loss: 3.1379e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.4701e-04 - val_loss: 3.1309e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.6811e-04 - val_loss: 3.1156e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.3582e-04 - val_loss: 3.0018e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3812e-04 - val_loss: 3.0433e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3593e-04 - val_loss: 3.6110e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3365e-04 - val_loss: 3.4327e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3572e-04 - val_loss: 3.3269e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3438e-04 - val_loss: 3.0679e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2554e-04 - val_loss: 3.1058e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3319e-04 - val_loss: 3.1792e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.2826e-04 - val_loss: 3.0477e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2149e-04 - val_loss: 3.4697e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2141e-04 - val_loss: 3.4902e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.3748e-04 - val_loss: 3.3657e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2763e-04 - val_loss: 3.1375e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2853e-04 - val_loss: 3.4303e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2056e-04 - val_loss: 3.2165e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.2591e-04 - val_loss: 3.1539e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.2155e-04 - val_loss: 3.2148e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.1365e-04 - val_loss: 3.0497e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.3531e-04 - val_loss: 3.3068e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.1934e-04 - val_loss: 3.0809e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.3335e-04 - val_loss: 3.3992e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.1935e-04 - val_loss: 3.3922e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 4.1494e-04 - val_loss: 3.0533e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.1525e-04 - val_loss: 3.1620e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 4.0895e-04 - val_loss: 3.0072e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.1624e-04 - val_loss: 2.9066e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.2460e-04 - val_loss: 3.2303e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 4.1939e-04 - val_loss: 3.0465e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.0923e-04 - val_loss: 2.9014e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.1142e-04 - val_loss: 3.0864e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 4.1371e-04 - val_loss: 2.8918e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.1962e-04 - val_loss: 3.0426e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.1481e-04 - val_loss: 3.4151e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 4.0613e-04 - val_loss: 2.9402e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.0912e-04 - val_loss: 2.9478e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.0263e-04 - val_loss: 2.8538e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 4.0329e-04 - val_loss: 2.9527e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.1398e-04 - val_loss: 3.1622e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.1077e-04 - val_loss: 2.9716e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.0596e-04 - val_loss: 3.0621e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.0381e-04 - val_loss: 3.1794e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.0836e-04 - val_loss: 2.9772e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.1372e-04 - val_loss: 2.9960e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 3.9989e-04 - val_loss: 2.8229e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 4.0606e-04 - val_loss: 2.9030e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 3.9419e-04 - val_loss: 3.4147e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 4.0094e-04 - val_loss: 3.0193e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.0936e-04 - val_loss: 3.1161e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 4.0347e-04 - val_loss: 2.9336e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 3.9739e-04 - val_loss: 2.9324e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 4.0242e-04 - val_loss: 2.8839e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 3.9577e-04 - val_loss: 3.0672e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 3.9983e-04 - val_loss: 2.9945e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 3.9352e-04 - val_loss: 2.8800e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 4.0129e-04 - val_loss: 2.9568e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 3.8855e-04 - val_loss: 2.9797e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 3.8860e-04 - val_loss: 2.8805e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 3.9524e-04 - val_loss: 3.0984e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 3.8736e-04 - val_loss: 2.7726e-04\n",
      "6944/6944 [==============================] - 0s 40us/step\n",
      "Now processing station number 159\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 14s 641us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 12/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 13/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 14/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/200\n",
      "22220/22220 [==============================] - 4s 178us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 18/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 21/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 23/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 24/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 25/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 26/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 27/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 28/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 29/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 30/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 31/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 32/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 33/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 34/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 35/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 36/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 37/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 38/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 39/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 40/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 41/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 42/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 43/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 44/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 45/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 46/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 47/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 48/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 49/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 50/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 51/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0010 - val_loss: 9.9417e-04\n",
      "Epoch 52/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.6771e-04\n",
      "Epoch 53/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.9181e-04\n",
      "Epoch 54/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0010 - val_loss: 9.6101e-04\n",
      "Epoch 55/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.9899e-04\n",
      "Epoch 56/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 57/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.6506e-04\n",
      "Epoch 58/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0010 - val_loss: 9.9567e-04\n",
      "Epoch 59/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 9.5410e-04\n",
      "Epoch 60/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.9801e-04\n",
      "Epoch 61/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0011 - val_loss: 9.8112e-04\n",
      "Epoch 62/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 63/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.5026e-04\n",
      "Epoch 64/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.5957e-04\n",
      "Epoch 65/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0010 - val_loss: 9.6591e-04\n",
      "Epoch 66/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 67/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.9056e-04\n",
      "Epoch 68/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.4447e-04\n",
      "Epoch 69/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.6312e-04\n",
      "Epoch 70/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 71/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.9285e-04 - val_loss: 9.2987e-04\n",
      "Epoch 72/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.7279e-04\n",
      "Epoch 73/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 9.5129e-04\n",
      "Epoch 74/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.9935e-04 - val_loss: 9.1934e-04\n",
      "Epoch 75/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.9909e-04 - val_loss: 0.0011\n",
      "Epoch 76/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.8371e-04 - val_loss: 9.1709e-04\n",
      "Epoch 77/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.8903e-04 - val_loss: 9.2951e-04\n",
      "Epoch 78/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.8553e-04 - val_loss: 9.2389e-04\n",
      "Epoch 79/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.9737e-04 - val_loss: 0.0012\n",
      "Epoch 80/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 81/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.9970e-04 - val_loss: 9.7606e-04\n",
      "Epoch 82/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.7706e-04 - val_loss: 0.0010\n",
      "Epoch 83/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.8848e-04 - val_loss: 9.1807e-04\n",
      "Epoch 84/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 85/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.9646e-04 - val_loss: 0.0010\n",
      "Epoch 86/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.8451e-04 - val_loss: 9.4471e-04\n",
      "Epoch 87/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.7594e-04 - val_loss: 9.3371e-04\n",
      "Epoch 88/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.5653e-04 - val_loss: 9.0083e-04\n",
      "Epoch 89/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.6876e-04 - val_loss: 9.0215e-04\n",
      "Epoch 90/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.7079e-04 - val_loss: 9.5544e-04\n",
      "Epoch 91/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.7255e-04 - val_loss: 9.8221e-04\n",
      "Epoch 92/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.5277e-04 - val_loss: 9.4873e-04\n",
      "Epoch 93/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.8981e-04 - val_loss: 0.0013\n",
      "Epoch 94/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.7248e-04 - val_loss: 9.1399e-04\n",
      "Epoch 95/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.8159e-04 - val_loss: 9.2625e-04\n",
      "Epoch 96/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.6457e-04 - val_loss: 9.2024e-04\n",
      "Epoch 97/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.6883e-04 - val_loss: 8.9350e-04\n",
      "Epoch 98/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.4510e-04 - val_loss: 8.9486e-04\n",
      "Epoch 99/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.5384e-04 - val_loss: 9.0136e-04\n",
      "Epoch 100/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.5509e-04 - val_loss: 0.0010\n",
      "Epoch 101/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.5003e-04 - val_loss: 9.5271e-04\n",
      "Epoch 102/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3245e-04 - val_loss: 8.8878e-04\n",
      "Epoch 103/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.4425e-04 - val_loss: 9.2841e-04\n",
      "Epoch 104/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.5961e-04 - val_loss: 8.9738e-04\n",
      "Epoch 105/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3553e-04 - val_loss: 9.1694e-04\n",
      "Epoch 106/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3183e-04 - val_loss: 9.0085e-04\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.6485e-04 - val_loss: 8.9462e-04\n",
      "Epoch 108/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.5238e-04 - val_loss: 9.5631e-04\n",
      "Epoch 109/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.3465e-04 - val_loss: 8.8258e-04\n",
      "Epoch 110/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.5351e-04 - val_loss: 9.0480e-04\n",
      "Epoch 111/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.6238e-04 - val_loss: 9.2286e-04\n",
      "Epoch 112/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.6665e-04 - val_loss: 9.7455e-04\n",
      "Epoch 113/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3535e-04 - val_loss: 9.0357e-04\n",
      "Epoch 114/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2814e-04 - val_loss: 8.9312e-04\n",
      "Epoch 115/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.6080e-04 - val_loss: 9.1171e-04\n",
      "Epoch 116/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3794e-04 - val_loss: 9.0558e-04\n",
      "Epoch 117/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.5116e-04 - val_loss: 9.2334e-04\n",
      "Epoch 118/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3308e-04 - val_loss: 9.5817e-04\n",
      "Epoch 119/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2157e-04 - val_loss: 8.7950e-04\n",
      "Epoch 120/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3171e-04 - val_loss: 9.0409e-04\n",
      "Epoch 121/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.6523e-04 - val_loss: 8.8165e-04\n",
      "Epoch 122/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2974e-04 - val_loss: 9.1455e-04\n",
      "Epoch 123/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.3154e-04 - val_loss: 8.7925e-04\n",
      "Epoch 124/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2903e-04 - val_loss: 8.7677e-04\n",
      "Epoch 125/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2017e-04 - val_loss: 8.5958e-04\n",
      "Epoch 126/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1989e-04 - val_loss: 8.9320e-04\n",
      "Epoch 127/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1505e-04 - val_loss: 8.9467e-04\n",
      "Epoch 128/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1473e-04 - val_loss: 8.6345e-04\n",
      "Epoch 129/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3190e-04 - val_loss: 8.7696e-04\n",
      "Epoch 130/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0892e-04 - val_loss: 9.0254e-04\n",
      "Epoch 131/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3572e-04 - val_loss: 8.9938e-04\n",
      "Epoch 132/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2630e-04 - val_loss: 9.3141e-04\n",
      "Epoch 133/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.3988e-04 - val_loss: 8.8102e-04\n",
      "Epoch 134/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0891e-04 - val_loss: 9.1896e-04\n",
      "Epoch 135/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1245e-04 - val_loss: 8.7144e-04\n",
      "Epoch 136/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1524e-04 - val_loss: 9.2567e-04\n",
      "Epoch 137/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0732e-04 - val_loss: 0.0010\n",
      "Epoch 138/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 9.2166e-04 - val_loss: 8.9398e-04\n",
      "Epoch 139/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1686e-04 - val_loss: 8.6964e-04\n",
      "Epoch 140/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2228e-04 - val_loss: 8.8166e-04\n",
      "Epoch 141/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.2543e-04 - val_loss: 9.1384e-04\n",
      "Epoch 142/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1377e-04 - val_loss: 8.6499e-04\n",
      "Epoch 143/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1187e-04 - val_loss: 9.5447e-04\n",
      "Epoch 144/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1878e-04 - val_loss: 8.7555e-04\n",
      "Epoch 145/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.2620e-04 - val_loss: 8.9366e-04\n",
      "Epoch 146/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0591e-04 - val_loss: 8.6634e-04\n",
      "Epoch 147/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0478e-04 - val_loss: 8.9836e-04\n",
      "Epoch 148/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1620e-04 - val_loss: 9.0322e-04\n",
      "Epoch 149/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1912e-04 - val_loss: 8.6319e-04\n",
      "Epoch 150/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.9999e-04 - val_loss: 8.7381e-04\n",
      "Epoch 151/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.9077e-04 - val_loss: 8.7325e-04\n",
      "Epoch 152/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1136e-04 - val_loss: 8.5349e-04\n",
      "Epoch 153/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.8536e-04 - val_loss: 8.6822e-04\n",
      "Epoch 154/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0262e-04 - val_loss: 9.5894e-04\n",
      "Epoch 155/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.9871e-04 - val_loss: 8.9873e-04\n",
      "Epoch 156/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.8520e-04 - val_loss: 8.5824e-04\n",
      "Epoch 157/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.8874e-04 - val_loss: 8.7075e-04\n",
      "Epoch 158/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.0620e-04 - val_loss: 9.0620e-04\n",
      "Epoch 159/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.8426e-04 - val_loss: 8.7454e-04\n",
      "Epoch 160/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.9890e-04 - val_loss: 8.4775e-04\n",
      "Epoch 161/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.8644e-04 - val_loss: 8.8364e-04\n",
      "Epoch 162/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 9.1817e-04 - val_loss: 8.6303e-04\n",
      "Epoch 163/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 9.0573e-04 - val_loss: 8.4176e-04\n",
      "Epoch 164/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 8.7887e-04 - val_loss: 8.5051e-04\n",
      "Epoch 165/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.7913e-04 - val_loss: 8.4891e-04\n",
      "Epoch 166/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.7198e-04 - val_loss: 9.1211e-04\n",
      "Epoch 167/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.8464e-04 - val_loss: 8.3589e-04\n",
      "Epoch 168/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6552e-04 - val_loss: 8.2838e-04\n",
      "Epoch 169/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.8282e-04 - val_loss: 8.6552e-04\n",
      "Epoch 170/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.8458e-04 - val_loss: 8.4702e-04\n",
      "Epoch 171/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.9294e-04 - val_loss: 8.7951e-04\n",
      "Epoch 172/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.6572e-04 - val_loss: 9.8422e-04\n",
      "Epoch 173/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.8047e-04 - val_loss: 8.5439e-04\n",
      "Epoch 174/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.7536e-04 - val_loss: 8.4058e-04\n",
      "Epoch 175/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6387e-04 - val_loss: 8.6419e-04\n",
      "Epoch 176/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6457e-04 - val_loss: 8.3700e-04\n",
      "Epoch 177/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.5701e-04 - val_loss: 8.2567e-04\n",
      "Epoch 178/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.7249e-04 - val_loss: 8.6511e-04\n",
      "Epoch 179/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6366e-04 - val_loss: 8.1903e-04\n",
      "Epoch 180/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.5323e-04 - val_loss: 8.2608e-04\n",
      "Epoch 181/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 8.4977e-04 - val_loss: 8.2126e-04\n",
      "Epoch 182/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.7367e-04 - val_loss: 8.5024e-04\n",
      "Epoch 183/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 8.6890e-04 - val_loss: 8.8261e-04\n",
      "Epoch 184/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6034e-04 - val_loss: 8.3712e-04\n",
      "Epoch 185/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.8632e-04 - val_loss: 8.1707e-04\n",
      "Epoch 186/200\n",
      "22220/22220 [==============================] - 3s 152us/step - loss: 8.6135e-04 - val_loss: 8.4090e-04\n",
      "Epoch 187/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6611e-04 - val_loss: 8.3723e-04\n",
      "Epoch 188/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.6965e-04 - val_loss: 8.1334e-04\n",
      "Epoch 189/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.4810e-04 - val_loss: 8.2401e-04\n",
      "Epoch 190/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.5579e-04 - val_loss: 8.3035e-04\n",
      "Epoch 191/200\n",
      "22220/22220 [==============================] - 4s 158us/step - loss: 8.3914e-04 - val_loss: 8.2798e-04\n",
      "Epoch 192/200\n",
      "22220/22220 [==============================] - 3s 157us/step - loss: 8.5881e-04 - val_loss: 8.4145e-04\n",
      "Epoch 193/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.4220e-04 - val_loss: 8.0580e-04\n",
      "Epoch 194/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.7619e-04 - val_loss: 8.6666e-04\n",
      "Epoch 195/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.5666e-04 - val_loss: 8.2179e-04\n",
      "Epoch 196/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.3927e-04 - val_loss: 8.5230e-04\n",
      "Epoch 197/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 8.3295e-04 - val_loss: 8.4641e-04\n",
      "Epoch 198/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.4130e-04 - val_loss: 8.0319e-04\n",
      "Epoch 199/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.5193e-04 - val_loss: 8.1009e-04\n",
      "Epoch 200/200\n",
      "22220/22220 [==============================] - 3s 153us/step - loss: 8.4752e-04 - val_loss: 8.2213e-04\n",
      "6944/6944 [==============================] - 0s 39us/step\n",
      "Now processing station number 201\n",
      "Train on 22220 samples, validate on 5556 samples\n",
      "Epoch 1/200\n",
      "22220/22220 [==============================] - 15s 663us/step - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 2/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 3/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 4/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 5/200\n",
      "22220/22220 [==============================] - 3s 155us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 6/200\n",
      "22220/22220 [==============================] - 3s 154us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 7/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 8/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 9/200\n",
      "22220/22220 [==============================] - 3s 156us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 10/200\n",
      "22220/22220 [==============================] - 4s 188us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 11/200\n",
      "22220/22220 [==============================] - 4s 184us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 12/200\n",
      "15360/22220 [===================>..........] - ETA: 1s - loss: 0.0023"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b8f8811ff08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 스케일링을 트레이닝의 값에 대해서만 적용해야 한다는 기사 발견\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mSMAPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstation_number\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstation_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SMAPE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMAPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bfbb4768b902>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# run model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = pd.read_csv('./data/result.csv', encoding='utf-8')\n",
    "station_numbers = result['station_number'].tolist()\n",
    "\n",
    "for i in range(len(station_numbers)):\n",
    "    \n",
    "    station_number = station_numbers[i]\n",
    "    result = pd.read_csv('./data/result.csv', encoding='utf-8')\n",
    "    \n",
    "    # skip stations already processed\n",
    "    if result[result['station_number'] == station_number].at[i, 'SMAPE'] != 0.0:\n",
    "        continue\n",
    "        \n",
    "    print(\"Now processing station number %d\" % station_number)\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df = pd.read_csv('./data/departure/%d_2008_to_2017.csv' % station_number,encoding='utf-8', dtype='float64')\n",
    "    data = np.concatenate(scaler.fit_transform(df.values.reshape(-1,1))) # 스케일링을 트레이닝의 값에 대해서만 적용해야 한다는 기사 발견\n",
    "    \n",
    "    SMAPE, RMSE = run_model(data)\n",
    "    \n",
    "    result.loc[result.station_number == station_number, 'SMAPE'] = SMAPE\n",
    "    result.loc[result.station_number == station_number, 'RMSE'] = RMSE\n",
    "    \n",
    "    result.to_csv('./data/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "#plt.title('model loss')\n",
    "#plt.ylabel('loss')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'val'], loc='upper left')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
